---
title: "UKAlc_Merging_Descriptives"
author: "Anna Patterson"
date: "2023-09-28"
output: html_document
---

rm(list = ls())
```{r}
#libraries
library(tidyverse)
library(dplyr)
library(tidyr)
library(stringr)
knitr::opts_chunk$set(echo = TRUE)

#Anisha's Paths


# am_qual <- read.csv("C:/Users/anish/Box/00 - CLEAR Lab (Locked Folders)/02 - Data Management, Analysis, and Papers/Studies_Projects/UKALC/02_datasets/UKALC_DAILY/02_data_prep_workspace/AM_Qualtrics_csv.csv")
# 
# pm_qual <- read.csv("C:/Users/anish/Box/00 - CLEAR Lab (Locked Folders)/02 - Data Management, Analysis, and Papers/Studies_Projects/UKALC/02_datasets/UKALC_DAILY/02_data_prep_workspace/PM_Qualtrics_csv.csv")
# 
# am_rc <- read.csv("C:/Users/anish/Box/00 - CLEAR Lab (Locked Folders)/02 - Data Management, Analysis, and Papers/Studies_Projects/UKALC/02_datasets/UKALC_DAILY/02_data_prep_workspace/AM_REDCap_csv.csv")
# 
# pm_rc <- read.csv("C:/Users/anish/Box/00 - CLEAR Lab (Locked Folders)/02 - Data Management, Analysis, and Papers/Studies_Projects/UKALC/02_datasets/UKALC_DAILY/02_data_prep_workspace/PM_REDCap_csv.csv")


#Anna's Paths

am_qual <- read.csv("/Users/apatte21/Library/CloudStorage/Box-Box/00 - CLEAR Lab (Locked Folders)/02 - Data Management, Analysis, and Papers/Studies_Projects/UKALC/02_datasets/UKALC_DAILY/02_data_prep_workspace/AM_Qualtrics_csv.csv")

pm_qual <- read.csv("/Users/apatte21/Library/CloudStorage/Box-Box/00 - CLEAR Lab (Locked Folders)/02 - Data Management, Analysis, and Papers/Studies_Projects/UKALC/02_datasets/UKALC_DAILY/02_data_prep_workspace/PM_Qualtrics_csv.csv")

am_rc <- read.csv("/Users/apatte21/Library/CloudStorage/Box-Box/00 - CLEAR Lab (Locked Folders)/02 - Data Management, Analysis, and Papers/Studies_Projects/UKALC/02_datasets/UKALC_DAILY/02_data_prep_workspace/AM_REDCap_csv.csv")

pm_rc <- read.csv("/Users/apatte21/Library/CloudStorage/Box-Box/00 - CLEAR Lab (Locked Folders)/02 - Data Management, Analysis, and Papers/Studies_Projects/UKALC/02_datasets/UKALC_DAILY/02_data_prep_workspace/PM_REDCap_csv.csv")
```

ID's in am_qual: 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 126

ID's in a_rc: [1] "123"       "124"       "125"       "125b"      "125c"      "125d"      "127"       "127 (new)" "128"      
[10] "129"       "130"       "131"       "132"       "133"       "134"       "134b"      "135"       "136"      
[19] "138"       "139"       "139b"      "140"       "141"       "142"       "142b"      "143"       "144"      
[28] "145"       "146"       "147"       "148"       "149"       "150"       "152"       "153"       "154"      
[37] "155"       "156"       "157"       "158"       "159"       "160"       "161"       "162"       "163"      
[46] "164"       "165"       "166"       "166a"      "166b"      "167"       "168"       "169"       "170"      
[55] "171"       "172"       "173"       "174"       "175"       "176"       "177"       "178"       "179"      
[64] "180"       "181"       "182"       "183"       "184"       "185"   

ID's in pm_qual: 101 102 103 104 105 106 107 108 109 111 112 113 114 115 116 117 118 119 120 121 122 126 

ID's in pm_rc: [1] "123"       "124"       "125"       "125b"      "125c"      "125d"      "127"       "127 (new)" "128"      
[10] "129"       "130"       "131"       "132"       "133"       "134"       "134b"      "135"       "136"      
[19] "138"       "139"       "139b"      "140"       "141"       "142"       "142b"      "143"       "144"      
[28] "145"       "146"       "147"       "148"       "149"       "150"       "152"       "153"       "154"      
[37] "155"       "156"       "157"       "158"       "159"       "160"       "161"       "162"       "163"      
[46] "164"       "165"       "166"       "166a"      "166b"      "167"       "168"       "169"       "170"      
[55] "171"       "172"       "173"       "174"       "175"       "176"       "177"       "178"       "179"      
[64] "180"       "181"       "182"       "183"       "184"       "185"    



#IDs in am qualtrics are numerical, IDs in rc are string form -- letters at end of some IDs indicate different sessions of same participant 
```{r}
am_data <- merge(am_qual, am_rc, by = c("ID", "DateTime"), all = T)

pm_data <- merge(pm_qual, pm_rc, by = c("ID", "DateTime"), all = T)

```
#view overlap between am and pm data 
#See how many unique IDs are in each dataset 
```{r}
intersect(am_data$ID, pm_data$ID)

setdiff(am_data$ID, pm_data$ID)

am_pm_part <- intersect(am_data$ID, pm_data$ID)
length(am_pm_part)

am_data$ID <- gsub("[^0-9.-]", "", am_data$ID)
pm_data$ID <- gsub("[^0-9.-]", "", pm_data$ID)

#seeing how many IDs are in each data set, viewed the output and saw they included NA in the calculation, so subtracted 1 from final calculation 
length(unique(am_data$ID))
length(unique(pm_data$ID))
```

#Before correcting for duplicates, we have n = 83 for am data and n = 82 for pm data 

```{r}
#separate datetime variable 
am_data[c('daterated', 'time')] <- str_split_fixed(am_data$DateTime, ' ', 2)
pm_data[c('daterated', 'time')] <- str_split_fixed(pm_data$DateTime, ' ', 2)
```

```{r}
#Transform daterated into a date variable so R can recognize as date variable
am_data$daterated <- lubridate::mdy(am_data$daterated)
pm_data$daterated <- lubridate::mdy(pm_data$daterated)

#Remove DateTime column from df 
am_data = subset(am_data, select = -c(DateTime))
pm_data = subset(pm_data, select = -c(DateTime))
```

```{r}
replace_empty_with_na <- function(data) {
  data %>% mutate_if(is.character, ~ ifelse(. == "", NA, .))
}

# Replace empty strings with NA in your dataset
# data1 <- replace_empty_with_na(data1)
# data2 <- replace_empty_with_na(data2)

xymerge <- function(dat) {
  # Create a logical vector indicating which column names end in ".x"
  x_cols <- grepl("\\.x$", names(dat))
  
  # Loop over each x column and apply the ifelse function
  for (x_col in names(dat)[x_cols]) {
    # Extract the corresponding y column name
    y_col <- gsub("\\.x$", ".y", x_col)
    
    # Create a new column name by removing the .x suffix
    new_col <- gsub("\\.x$", "", x_col)
    
    # Apply the ifelse function to the x and y columns and assign the result to the new column
    dat[[new_col]] <- ifelse(is.na(dat[[x_col]]), dat[[y_col]], dat[[x_col]])
    
    # Remove the x and y columns from the dataframe
    dat[[x_col]] <- NULL
    dat[[y_col]] <- NULL
  }
  
  # Return the updated data frame
  return(dat)
}

#replace empty with NA so they're coded the same for subsequent functions 
am_data <- replace_empty_with_na(am_data)
pm_data <- replace_empty_with_na(pm_data)
#consolidate xy variable names that existed as a byproduct of merging the two datasets with the same column names
am_data <- xymerge(am_data)
pm_data <- xymerge(pm_data)
```

#relocate daterated to be after ID and remove time column 
```{r}
am_data <- am_data %>% 
  relocate(daterated, .after = ID) 
pm_data <- pm_data %>% 
  relocate(daterated, .after = ID) 

```



```{r}
#Add _am and _pm suffixes to each dataset 
colnames(am_data) <- paste(colnames(am_data), "am", sep="_")

colnames(pm_data) <- paste(colnames(pm_data), "pm", sep="_")
```

```{r}
#rename daterated and ID to drop the _am and _pm suffixes 
colnames(am_data)[colnames(am_data) == "daterated_am"] ="daterated"
colnames(pm_data)[colnames(pm_data) == "daterated_pm"] ="daterated"

colnames(am_data)[colnames(am_data) == "ID_am"] ="ID"
colnames(pm_data)[colnames(pm_data) == "ID_pm"] ="ID"
```


#Remove rows where everything is NA except daterated, time, and ID
```{r}
am_data <- am_data %>%
  filter(!is.na(ID) | !is.na(daterated) | !is.na(time_am))
conflicts_prefer(dplyr::filter) 

pm_data <- pm_data %>%
  filter(!is.na(ID) | !is.na(daterated) | !is.na(time_pm))
conflicts_prefer(dplyr::filter) 

#Anna tried the above code 10/11/23, no change to either df but perhaps no rows fit this criteria 

# am_data <- am_data %>% drop_na(daterated, ID)
# pm_data <- pm_data %>% drop_na(daterated, ID)

```

#Find Duplicates in Dates per ID 
```{r}

result.am <- am_data %>%
  group_by(ID, daterated) %>%
  summarise(observations = n())

dupdate_am <- subset(result.am, observations != 1)

result.pm <- pm_data %>%
  group_by(ID, daterated) %>%
  summarise(observations = n())

dupdate_pm <- subset(result.pm, observations != 1)

```

#Remove rows so that we no longer have >1 submission per am or pm data per date. Kept earliest timestamp if all submissions are identical, or kept most complete form if some are more completed than others. 
```{r}
#ID 106 
am_data %>%
  filter(ID == 106 & daterated == ymd("2021-05-09"))

#remove duplicates for 106 on 2021-05-09 
am_data <- am_data[!(am_data$ID == 106 & am_data$daterated == "2021-05-09" & am_data$time_am == "10:02"), ]
am_data <- am_data[!(am_data$ID == 106 & am_data$daterated == "2021-05-09" & am_data$time_am == "9:59"), ]

#remove duplicates for 106 on 2021-05-18 
am_data %>%
  filter(ID == 106 & daterated == ymd("2021-05-18"))

am_data <- am_data[!(am_data$ID == 106 & am_data$daterated == "2021-05-18" & am_data$time_am == "6:35"), ]

#remove duplicates for 106 on 2021-05-20 
am_data %>%
  filter(ID == 106 & daterated == ymd("2021-05-20"))

am_data <- am_data[!(am_data$ID == 106 & am_data$daterated == "2021-05-20" & am_data$time_am == "4:50"), ]

#remove duplicates for 106 on 2021-05-24 
am_data %>%
  filter(ID == 106 & daterated == ymd("2021-05-24"))

am_data <- am_data[!(am_data$ID == 106 & am_data$daterated == "2021-05-24" & am_data$time_am == "21:59"), ]
am_data <- am_data[!(am_data$ID == 106 & am_data$daterated == "2021-05-24" & am_data$time_am == "22:00"), ]
am_data <- am_data[!(am_data$ID == 106 & am_data$daterated == "2021-05-24" & am_data$time_am == "22:02"), ]

#remove duplicates for 112 on 2021-06-28 
am_data %>%
  filter(ID == 112 & daterated == ymd("2021-06-28"))

am_data <- am_data[!(am_data$ID == 112 & am_data$daterated == "2021-06-28" & am_data$time_am == "4:58"), ]

#remove duplicates for 112 on 2021-07-11
am_data %>%
  filter(ID == 112 & daterated == ymd("2021-07-11"))

am_data <- am_data[!(am_data$ID == 112 & am_data$daterated == "2021-07-11" & am_data$time_am == "18:38"), ] 

#remove duplicates for 113 on 2021-06-23 
am_data %>%
  filter(ID == 113 & daterated == ymd("2021-06-23"))

am_data <- am_data[!(am_data$ID == 113 & am_data$daterated == "2021-06-23" & am_data$time_am == "14:34"), ] 

#remove duplicates for 113 on 2021-07-07 
am_data %>%
  filter(ID == 113 & daterated == ymd("2021-07-07"))

am_data <- am_data[!(am_data$ID == 113 & am_data$daterated == "2021-07-07" & am_data$time_am == "11:57"), ] 

#remove duplicates for 113 on 2021-07-21
am_data %>%
  filter(ID == 113 & daterated == ymd("2021-07-21"))

am_data <- am_data[!(am_data$ID == 113 & am_data$daterated == "2021-07-21" & am_data$time_am == "11:12"), ] 

#remove duplicates for 114 on 2021-06-29
am_data %>%
  filter(ID == 114 & daterated == ymd("2021-06-29"))

am_data <- am_data[!(am_data$ID == 114 & am_data$daterated == "2021-06-29" & am_data$time_am == "22:00"), ] 

#remove duplicates for 114 on 2021-07-01 
am_data %>%
  filter(ID == 114 & daterated == ymd("2021-07-01"))

am_data <- am_data[!(am_data$ID == 114 & am_data$daterated == "2021-07-01 " & am_data$time_am == "9:33"), ] 

#remove duplicates for 114 on 2021-07-04 
am_data %>%
  filter(ID == 114 & daterated == ymd("2021-07-04"))

am_data <- am_data[!(am_data$ID == 114 & am_data$daterated == "2021-07-04" & am_data$time_am == "5:58"), ] 

#remove duplicates for 114 on 2021-07-06
am_data %>%
  filter(ID == 114 & daterated == ymd("2021-07-06"))

am_data <- am_data[!(am_data$ID == 114 & am_data$daterated == "2021-07-06" & am_data$time_am == "4:52"), ] 

#remove duplicates for 114 on 2021-07-09 
am_data %>%
  filter(ID == 114 & daterated == ymd("2021-07-09"))

am_data <- am_data[!(am_data$ID == 114 & am_data$daterated == "2021-07-09" & am_data$time_am == "21:44"), ] 
am_data <- am_data[!(am_data$ID == 114 & am_data$daterated == "2021-07-09" & am_data$time_am == "21:45"), ] 

#remove duplicates for 114 on 2021-07-15
am_data %>%
  filter(ID == 114 & daterated == ymd("2021-07-15"))

am_data <- am_data[!(am_data$ID == 114 & am_data$daterated == "2021-07-15" & am_data$time_am == "7:44"), ] 

#remove duplicates for 115 on 2021-06-24 
am_data %>%
  filter(ID == 115 & daterated == ymd("2021-06-24"))

am_data <- am_data[!(am_data$ID == 115 & am_data$daterated == "2021-06-24" & am_data$time_am == "6:52"), ] 

#remove duplicates for 115 on 2021-06-27
am_data %>%
  filter(ID == 115 & daterated == ymd("2021-06-27"))

am_data <- am_data[!(am_data$ID == 115 & am_data$daterated == "2021-06-27" & am_data$time_am == "8:27"), ] 

#remove duplicates for 115 on 2021-07-01
am_data %>%
  filter(ID == 115 & daterated == ymd("2021-07-01"))

am_data <- am_data[!(am_data$ID == 115 & am_data$daterated == "2021-07-01" & am_data$time_am == "19:53"), ] 

#remove duplicates for 115 on 2021-07-04
am_data %>%
  filter(ID == 115 & daterated == ymd("2021-07-04"))

am_data <- am_data[!(am_data$ID == 115 & am_data$daterated == "2021-07-04" & am_data$time_am == "3:00"), ] 

#remove duplicates for 115 on 2021-07-09 
am_data %>%
  filter(ID == 115 & daterated == ymd("2021-07-09"))

am_data <- am_data[!(am_data$ID == 115 & am_data$daterated == "2021-07-09" & am_data$time_am == "21:49"), ] 
am_data <- am_data[!(am_data$ID == 115 & am_data$daterated == "2021-07-09" & am_data$time_am == "21:52"), ] 
am_data <- am_data[!(am_data$ID == 115 & am_data$daterated == "2021-07-09" & am_data$time_am == "21:55"), ] 
am_data <- am_data[!(am_data$ID == 115 & am_data$daterated == "2021-07-09" & am_data$time_am == "22:01"), ] 

#remove duplicates for 115 on 2021-07-11
am_data %>%
  filter(ID == 115 & daterated == ymd("2021-07-11"))

am_data <- am_data[!(am_data$ID == 115 & am_data$daterated == "2021-07-11" & am_data$time_am == "8:38"), ] 
am_data <- am_data[!(am_data$ID == 115 & am_data$daterated == "2021-07-11" & am_data$time_am == "8:41"), ] 

#remove duplicates for 115 on 2021-07-20 
am_data %>%
  filter(ID == 115 & daterated == ymd("2021-07-20"))

am_data <- am_data[!(am_data$ID == 115 & am_data$daterated == "2021-07-20" & am_data$time_am == "6:50"), ] 
am_data <- am_data[!(am_data$ID == 115 & am_data$daterated == "2021-07-20" & am_data$time_am == "6:57"), ] 
am_data <- am_data[!(am_data$ID == 115 & am_data$daterated == "2021-07-20" & am_data$time_am == "7:00"), ] 
am_data <- am_data[!(am_data$ID == 115 & am_data$daterated == "2021-07-20" & am_data$time_am == "7:04"), ] 
am_data <- am_data[!(am_data$ID == 115 & am_data$daterated == "2021-07-20" & am_data$time_am == "7:06"), ] 
am_data <- am_data[!(am_data$ID == 115 & am_data$daterated == "2021-07-20" & am_data$time_am == "7:09"), ] 
am_data <- am_data[!(am_data$ID == 115 & am_data$daterated == "2021-07-20" & am_data$time_am == "7:13"), ] 

#remove duplicates for 118 on 2021-08-08
am_data %>%
  filter(ID == 118 & daterated == ymd("2021-08-08"))

am_data <- am_data[!(am_data$ID == 118 & am_data$daterated == "2021-08-08" & am_data$time_am == "12:29"), ] 

#remove duplicates for 119 on 2021-08-27
am_data %>%
  filter(ID == 119 & daterated == ymd("2021-08-27"))

am_data <- am_data[!(am_data$ID == 119 & am_data$daterated == "2021-08-27" & am_data$time_am == "21:42"), ] 

#remove duplicates for 123 on 2021-08-31
am_data %>%
  filter(ID == 123 & daterated == ymd("2021-08-31"))

am_data <- am_data[!(am_data$ID == 123 & am_data$daterated == "2021-08-31" & am_data$time_am == "5:05"), ] 

#remove duplicates for 131 on 2021-10-17 
am_data %>%
  filter(ID == 131 & daterated == ymd("2021-10-17 "))

am_data <- am_data[!(am_data$ID == 131 & am_data$daterated == "2021-10-17" & am_data$time_am == "22:16"), ] 

#remove duplicates for ID 136 on 2021-11-29 
am_data %>%
  filter(ID == 136 & daterated == ymd("2021-11-29"))

am_data <- am_data[!(am_data$ID == 136 & am_data$daterated == "2021-11-29" & am_data$time_am == "12:56"), ] 

#remove duplicates for ID 141 on 2022-02-01
am_data %>%
  filter(ID == 141 & daterated == ymd("2022-02-01"))

am_data <- am_data[!(am_data$ID == 141 & am_data$daterated == "2022-02-01" & am_data$time_am == "7:30"), ] 

```

#remove IDs = NA 
```{r}
#note that these both didn't work 
#am_data <- am_data[!(is.na(am_data$ID)), ] 
#am_data <- am_data[!(am_data$ID == NA), ] 
```


#Anisha's way to investigate IDs in result_am and result_pm in which obs >1 
#Note that she wrote this with the old column names - will adjust based on final column naming scheme 
pm_data %>%  
  filter(id==[INSERT ID] & daterated==mdy("[INSERT DATE]"))

am_data %>%
  filter(id==[INSERT ID] & daterated==mdy("[INSERT DATE]"))
  
Remove by time using subset. If they are exactly the same, keep the earliest one. If not, keep the most complete one. 


#Drop Time Variable 
```{r}
am_data = subset(am_data, select=-c(time_am))

pm_data = subset(pm_data, select=-c(time_pm))
```

#drop ID 127 per Annie Griffith's recommendation (not much data for this ID)
```{r}

am_data <- subset(am_data, ID != 127)

pm_data <- subset(pm_data, ID != 127)

```



#IDs in both am and pm datasets: 
[1] "101"       "102"       "103"       "104"       "105"       "106"       "107"       "108"       "109"      
[10] "111"       "112"       "113"       "114"       "115"       "116"       "117"       "118"       "119"      
[19] "120"       "121"       "122"       "123"       "124"       "125"       "125b"      "125c"      "125d"     
[28] "126"       "127"       "127 (new)" "128"       "129"       "130"       "131"       "132"       "133"      
[37] "134"       "134b"      "135"       "136"       "138"       "139"       "139b"      "140"       "141"      
[46] "142"       "142b"      "143"       "144"       "145"       "146"       "147"       "148"       "149"      
[55] "150"       "152"       "153"       "154"       "155"       "156"       "157"       "158"       "159"      
[64] "160"       "161"       "162"       "163"       "164"       "165"       "166"       "166a"      "166b"     
[73] "167"       "168"       "169"       "170"       "171"       "172"       "173"       "174"       "175"      
[82] "176"       "177"       "178"       "179"       "180"       "181"       "182"       "183"       "184"      
[91] "185"  



