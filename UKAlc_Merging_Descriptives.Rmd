---
title: "UKAlc_Merging_Descriptives"
author: "Anna Patterson"
date: "2023-09-28"
output: html_document
---

rm(list = ls())
```{r}
#libraries
library(tidyverse)
library(dplyr)
library(tidyr)
library(stringr)
knitr::opts_chunk$set(echo = TRUE)

#Anisha's Paths


# am_qual <- read.csv("C:/Users/anish/Box/00 - CLEAR Lab (Locked Folders)/02 - Data Management, Analysis, and Papers/Studies_Projects/UKALC/02_datasets/UKALC_DAILY/02_data_prep_workspace/AM_Qualtrics_csv.csv")
# 
# pm_qual <- read.csv("C:/Users/anish/Box/00 - CLEAR Lab (Locked Folders)/02 - Data Management, Analysis, and Papers/Studies_Projects/UKALC/02_datasets/UKALC_DAILY/02_data_prep_workspace/PM_Qualtrics_csv.csv")
# 
# am_rc <- read.csv("C:/Users/anish/Box/00 - CLEAR Lab (Locked Folders)/02 - Data Management, Analysis, and Papers/Studies_Projects/UKALC/02_datasets/UKALC_DAILY/02_data_prep_workspace/AM_REDCap_csv.csv")
# 
# pm_rc <- read.csv("C:/Users/anish/Box/00 - CLEAR Lab (Locked Folders)/02 - Data Management, Analysis, and Papers/Studies_Projects/UKALC/02_datasets/UKALC_DAILY/02_data_prep_workspace/PM_REDCap_csv.csv")


#Anna's Paths

am_qual <- read.csv("/Users/apatte21/Library/CloudStorage/Box-Box/00 - CLEAR Lab (Locked Folders)/02 - Data Management, Analysis, and Papers/Studies_Projects/UKALC/02_datasets/UKALC_DAILY/02_data_prep_workspace/AM_Qualtrics_csv.csv")


pm_qual <- read.csv("/Users/apatte21/Library/CloudStorage/Box-Box/00 - CLEAR Lab (Locked Folders)/02 - Data Management, Analysis, and Papers/Studies_Projects/UKALC/02_datasets/UKALC_DAILY/02_data_prep_workspace/PM_Qualtrics_csv.csv")

am_rc <- read.csv("/Users/apatte21/Library/CloudStorage/Box-Box/00 - CLEAR Lab (Locked Folders)/02 - Data Management, Analysis, and Papers/Studies_Projects/UKALC/02_datasets/UKALC_DAILY/02_data_prep_workspace/AM_REDCap_csv.csv")

pm_rc <- read.csv("/Users/apatte21/Library/CloudStorage/Box-Box/00 - CLEAR Lab (Locked Folders)/02 - Data Management, Analysis, and Papers/Studies_Projects/UKALC/02_datasets/UKALC_DAILY/02_data_prep_workspace/PM_REDCap_csv.csv")
```

ID's in am_qual: 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 126

ID's in a_rc: [1] "123"       "124"       "125"       "125b"      "125c"      "125d"      "127"       "127 (new)" "128"      
[10] "129"       "130"       "131"       "132"       "133"       "134"       "134b"      "135"       "136"      
[19] "138"       "139"       "139b"      "140"       "141"       "142"       "142b"      "143"       "144"      
[28] "145"       "146"       "147"       "148"       "149"       "150"       "152"       "153"       "154"      
[37] "155"       "156"       "157"       "158"       "159"       "160"       "161"       "162"       "163"      
[46] "164"       "165"       "166"       "166a"      "166b"      "167"       "168"       "169"       "170"      
[55] "171"       "172"       "173"       "174"       "175"       "176"       "177"       "178"       "179"      
[64] "180"       "181"       "182"       "183"       "184"       "185"   

ID's in pm_qual: 101 102 103 104 105 106 107 108 109 111 112 113 114 115 116 117 118 119 120 121 122 126 

ID's in pm_rc: [1] "123"       "124"       "125"       "125b"      "125c"      "125d"      "127"       "127 (new)" "128"      
[10] "129"       "130"       "131"       "132"       "133"       "134"       "134b"      "135"       "136"      
[19] "138"       "139"       "139b"      "140"       "141"       "142"       "142b"      "143"       "144"      
[28] "145"       "146"       "147"       "148"       "149"       "150"       "152"       "153"       "154"      
[37] "155"       "156"       "157"       "158"       "159"       "160"       "161"       "162"       "163"      
[46] "164"       "165"       "166"       "166a"      "166b"      "167"       "168"       "169"       "170"      
[55] "171"       "172"       "173"       "174"       "175"       "176"       "177"       "178"       "179"      
[64] "180"       "181"       "182"       "183"       "184"       "185"    



#IDs in am qualtrics are numerical, IDs in rc are string form -- letters at end of some IDs indicate different sessions of same participant 
```{r}
am_data <- merge(am_qual, am_rc, by = c("ID", "DateTime"), all = T)

pm_data <- merge(pm_qual, pm_rc, by = c("ID", "DateTime"), all = T)

```
#view overlap between am and pm data 
#See how many unique IDs are in each dataset 
```{r}
intersect(am_data$ID, pm_data$ID)

setdiff(am_data$ID, pm_data$ID)

am_pm_part <- intersect(am_data$ID, pm_data$ID)
length(am_pm_part)

am_data$ID <- gsub("[^0-9.-]", "", am_data$ID)
pm_data$ID <- gsub("[^0-9.-]", "", pm_data$ID)

#seeing how many IDs are in each data set, viewed the output and saw they included NA in the calculation, so subtracted 1 from final calculation 
length(unique(am_data$ID))
length(unique(pm_data$ID))
```

#After correcting for duplicates, we have n = 83 for am data and n = 82 for pm data 

```{r}
#This worked last week but when I viewed the data it seemed not to? (10/03/2023)
am_data[c('daterated', 'time')] <- str_split_fixed(am_data$DateTime, ' ', 2)
pm_data[c('daterated', 'time')] <- str_split_fixed(pm_data$DateTime, ' ', 2)

View(am_data)
```

```{r}
#Transform daterated into a date variable so R can recognize as date variable
am_data$daterated <- lubridate::mdy(am_data$daterated)
pm_data$daterated <- lubridate::mdy(pm_data$daterated)

#Remove DateTime column from df 
am_data = subset(am_data, select = -c(DateTime))
pm_data = subset(pm_data, select = -c(DateTime))
```

```{r}
replace_empty_with_na <- function(data) {
  data %>% mutate_if(is.character, ~ ifelse(. == "", NA, .))
}

# Replace empty strings with NA in your dataset
# data1 <- replace_empty_with_na(data1)
# data2 <- replace_empty_with_na(data2)

xymerge <- function(dat) {
  # Create a logical vector indicating which column names end in ".x"
  x_cols <- grepl("\\.x$", names(dat))
  
  # Loop over each x column and apply the ifelse function
  for (x_col in names(dat)[x_cols]) {
    # Extract the corresponding y column name
    y_col <- gsub("\\.x$", ".y", x_col)
    
    # Create a new column name by removing the .x suffix
    new_col <- gsub("\\.x$", "", x_col)
    
    # Apply the ifelse function to the x and y columns and assign the result to the new column
    dat[[new_col]] <- ifelse(is.na(dat[[x_col]]), dat[[y_col]], dat[[x_col]])
    
    # Remove the x and y columns from the dataframe
    dat[[x_col]] <- NULL
    dat[[y_col]] <- NULL
  }
  
  # Return the updated data frame
  return(dat)
}

#replace empty with NA so they're coded the same for subsequent functions 
am_data <- replace_empty_with_na(am_data)
pm_data <- replace_empty_with_na(pm_data)
#consolidate xy variable names that existed as a byproduct of merging the two datasets with the same column names
am_data <- xymerge(am_data)
pm_data <- xymerge(pm_data)
```

#relocate daterated to be after ID and remove time column 
```{r}
am_data <- am_data %>% 
  relocate(daterated, .after = ID) 
pm_data <- pm_data %>% 
  relocate(daterated, .after = ID) 

am_data <- subset(am_data, select = -c(time))
pm_data <- subset(pm_data, select = -c(time))
```



```{r}
#Anna Re-did this code 10/3/2023
colnames(am_data) <- paste(colnames(am_data), "am", sep="_")
View(am_data)

colnames(pm_data) <- paste(colnames(pm_data), "pm", sep="_")
View(pm_data)
```

```{r}
#rename daterated and ID to drop the _am and _pm suffixes 
colnames(am_data)[colnames(am_data) == "daterated_am"] ="daterated"
colnames(pm_data)[colnames(pm_data) == "daterated_pm"] ="daterated"

colnames(am_data)[colnames(am_data) == "ID_am"] ="ID"
colnames(pm_data)[colnames(am_data) == "ID_pm"] ="ID"
```


#Remove rows where everything is NA except daterated and ID
```{r}
am_data <- am_data[!(rowSums(is.na(am_data) | am_data == "") == ncol(am_data) & !(am_data$ID != "" & am_data$daterated != "")), ]

pm_data <- pm_data[!(rowSums(is.na(pm_data) | pm_data == "") == ncol(pm_data) & !(pm_data$ID != "" & pm_data$daterated != "")), ]
```

#Find Duplicates in Dates per ID 
```{r}
dupsID = am_data %>%
  group_by(ID, daterated) %>%
  distinct(.keep_all = TRUE) %>%
  group_by(ID) %>%
  filter(n() == 1)  

result.am <- am_data %>%
  group_by(ID, daterated) %>%
  summarise(observations = n())

dupsID = pm_data %>%
  group_by(ID, daterated) %>%
  distinct(.keep_all = TRUE) %>%
  group_by(ID) %>%
  filter(n() == 1)  

result.pm <- pm_data %>%
  group_by(ID, daterated) %>%
  summarise(observations = n())

dupdate <- subset(result, observations != 1)
dupdate

am_data$check = am_data$ID_am %in% dupsID$ID_am
am_data$check

#Anna's investigation of IDs in which obs >1 
subset(am_data, id_am == 106 & daterated_am == ymd("2021-05-09"))

subset(am_data, id_am == 110)

```

#Anisha's way to investigate IDs in result_am and result_pm in which obs >1 
#Note that she wrote this with the old column names - will adjust based on final column naming scheme 
pm_data %>%  
  filter(id==[INSERT ID] & daterated==mdy("[INSERT DATE]"))

am_data %>%
  filter(id==[INSERT ID] & daterated==mdy("[INSERT DATE]"))


#Drop Time Variable 
```{r}
am_data = subset(am_data, select=-c(time_am))

pm_data = subset(pm_data, select=-c(time_pm))
```

#check to see if for one date, if person has more than 1 _am and 1_pm row 
```{r}
#changed daterated to Date because that's the column name - I feel like we should address this 
#got the error message, `summarise()` has grouped output by 'ID'. You can override using the `.groups` argument.
#it appears that this message is just a friendly reminder based off my findings and when I checked the data
result_am <- am_data %>% 
  group_by(ID, Date) %>% 
  summarise(observations = n())
result_pm <- pm_data %>% 
  group_by(ID, Date) %>% 
  summarise(observations = n())
```


#IDs in both am and pm datasets: 
[1] "101"       "102"       "103"       "104"       "105"       "106"       "107"       "108"       "109"      
[10] "111"       "112"       "113"       "114"       "115"       "116"       "117"       "118"       "119"      
[19] "120"       "121"       "122"       "123"       "124"       "125"       "125b"      "125c"      "125d"     
[28] "126"       "127"       "127 (new)" "128"       "129"       "130"       "131"       "132"       "133"      
[37] "134"       "134b"      "135"       "136"       "138"       "139"       "139b"      "140"       "141"      
[46] "142"       "142b"      "143"       "144"       "145"       "146"       "147"       "148"       "149"      
[55] "150"       "152"       "153"       "154"       "155"       "156"       "157"       "158"       "159"      
[64] "160"       "161"       "162"       "163"       "164"       "165"       "166"       "166a"      "166b"     
[73] "167"       "168"       "169"       "170"       "171"       "172"       "173"       "174"       "175"      
[82] "176"       "177"       "178"       "179"       "180"       "181"       "182"       "183"       "184"      
[91] "185"  

#IDs not in both am and pm datasets: [1] "110" 

#Check IDs with result_am and result_pm observations > 1 
```{r}
result_am
am_data %>%
  filter(id==[INSERT ID] & daterated==mdy("[INSERT DATE]"))

result_pm
pm_data %>%
  filter(id==[INSERT ID] & daterated==mdy("[INSERT DATE]"))
```

