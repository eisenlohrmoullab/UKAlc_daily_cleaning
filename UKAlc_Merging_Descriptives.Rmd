---
title: "UKAlc_Merging_Descriptives"
author: "Anna Patterson"
date: "2023-09-28"
output: html_document
---

rm(list = ls())
```{r}
#libraries
library(tidyverse)
library(dplyr)
library(tidyr)
library(stringr)
library(janitor)
library(lubridate)
## various sample MLMs
library(lme4)
library(nlme)
install.packages("lmerTest")
library(lmerTest) #to extract P values when lmer doesnt feel like showing them
library(performance) #to extract ICCs
library(emmeans) #for plotting interactions
knitr::opts_chunk$set(echo = TRUE)

#Anisha's Paths

# 
# am_qual <- read.csv("C:/Users/anish/Box/00 - CLEAR Lab (Locked Folders)/02 - Data Management, Analysis, and Papers/Studies_Projects/UKALC/02_datasets/UKALC_DAILY/02_data_prep_workspace/AM_Qualtrics_csv.csv")
# 
# pm_qual <- read.csv("C:/Users/anish/Box/00 - CLEAR Lab (Locked Folders)/02 - Data Management, Analysis, and Papers/Studies_Projects/UKALC/02_datasets/UKALC_DAILY/02_data_prep_workspace/PM_Qualtrics_csv.csv")
# 
# am_rc <- read.csv("C:/Users/anish/Box/00 - CLEAR Lab (Locked Folders)/02 - Data Management, Analysis, and Papers/Studies_Projects/UKALC/02_datasets/UKALC_DAILY/02_data_prep_workspace/AM_REDCap_csv.csv")
# 
# pm_rc <- read.csv("C:/Users/anish/Box/00 - CLEAR Lab (Locked Folders)/02 - Data Management, Analysis, and Papers/Studies_Projects/UKALC/02_datasets/UKALC_DAILY/02_data_prep_workspace/PM_REDCap_csv.csv")


#Anna's Paths

am_qual <- read.csv("/Users/apatte21/Library/CloudStorage/Box-Box/00 - CLEAR Lab (Locked Folders)/02 - Data Management, Analysis, and Papers/Studies_Projects/UKALC/02_datasets/UKALC_DAILY/02_data_prep_workspace/AM_Qualtrics_csv.csv")

pm_qual <- read.csv("/Users/apatte21/Library/CloudStorage/Box-Box/00 - CLEAR Lab (Locked Folders)/02 - Data Management, Analysis, and Papers/Studies_Projects/UKALC/02_datasets/UKALC_DAILY/02_data_prep_workspace/PM_Qualtrics_csv.csv")

am_rc <- read.csv("/Users/apatte21/Library/CloudStorage/Box-Box/00 - CLEAR Lab (Locked Folders)/02 - Data Management, Analysis, and Papers/Studies_Projects/UKALC/02_datasets/UKALC_DAILY/02_data_prep_workspace/AM_REDCap_csv.csv")

pm_rc <- read.csv("/Users/apatte21/Library/CloudStorage/Box-Box/00 - CLEAR Lab (Locked Folders)/02 - Data Management, Analysis, and Papers/Studies_Projects/UKALC/02_datasets/UKALC_DAILY/02_data_prep_workspace/PM_REDCap_csv.csv")
```

ID's in am_qual: 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 126

ID's in a_rc: [1] "123"       "124"       "125"       "125b"      "125c"      "125d"      "127"       "127 (new)" "128"      
[10] "129"       "130"       "131"       "132"       "133"       "134"       "134b"      "135"       "136"      
[19] "138"       "139"       "139b"      "140"       "141"       "142"       "142b"      "143"       "144"      
[28] "145"       "146"       "147"       "148"       "149"       "150"       "152"       "153"       "154"      
[37] "155"       "156"       "157"       "158"       "159"       "160"       "161"       "162"       "163"      
[46] "164"       "165"       "166"       "166a"      "166b"      "167"       "168"       "169"       "170"      
[55] "171"       "172"       "173"       "174"       "175"       "176"       "177"       "178"       "179"      
[64] "180"       "181"       "182"       "183"       "184"       "185"   

ID's in pm_qual: 101 102 103 104 105 106 107 108 109 111 112 113 114 115 116 117 118 119 120 121 122 126 

ID's in pm_rc: [1] "123"       "124"       "125"       "125b"      "125c"      "125d"      "127"       "127 (new)" "128"      
[10] "129"       "130"       "131"       "132"       "133"       "134"       "134b"      "135"       "136"      
[19] "138"       "139"       "139b"      "140"       "141"       "142"       "142b"      "143"       "144"      
[28] "145"       "146"       "147"       "148"       "149"       "150"       "152"       "153"       "154"      
[37] "155"       "156"       "157"       "158"       "159"       "160"       "161"       "162"       "163"      
[46] "164"       "165"       "166"       "166a"      "166b"      "167"       "168"       "169"       "170"      
[55] "171"       "172"       "173"       "174"       "175"       "176"       "177"       "178"       "179"      
[64] "180"       "181"       "182"       "183"       "184"       "185"    



#IDs in am qualtrics are numerical, IDs in rc are string form -- letters at end of some IDs indicate different sessions of same participant 
```{r}
am_data <- merge(am_qual, am_rc, by = c("ID", "DateTime"), all = T)

pm_data <- merge(pm_qual, pm_rc, by = c("ID", "DateTime"), all = T)

```
#view overlap between am and pm data 
#See how many unique IDs are in each dataset 
```{r}
intersect(am_data$ID, pm_data$ID)

setdiff(am_data$ID, pm_data$ID)

am_pm_part <- intersect(am_data$ID, pm_data$ID)
length(am_pm_part)

am_data$ID <- gsub("[^0-9.-]", "", am_data$ID)
pm_data$ID <- gsub("[^0-9.-]", "", pm_data$ID)

#seeing how many IDs are in each data set, viewed the output and saw they included NA in the calculation, so subtracted 1 from final calculation 
length(unique(am_data$ID))
length(unique(pm_data$ID))
```

#Before correcting for duplicates, we have n = 83 for am data and n = 82 for pm data 

```{r}
#separate datetime variable 
am_data[c('daterated', 'time')] <- str_split_fixed(am_data$DateTime, ' ', 2)
pm_data[c('daterated', 'time')] <- str_split_fixed(pm_data$DateTime, ' ', 2)
```

```{r}
#first step change time character to a time-realized variable 
pm_data$time <- lubridate::hm(pm_data$time)
pm_data$daterated <- lubridate::mdy(pm_data$daterated)

#flag observations that were done before 12pm 
pm_data <- pm_data %>% mutate(pm_data, b4noon = ifelse(time < lubridate::hm("12:00"),1, 0)) 

#if b4noon = 1, change pm_data$daterated - 1

pm_data <- pm_data %>%
  mutate(daterated = case_when(
    b4noon == 1 ~ daterated -1,
    TRUE ~ daterated
  ))
```

```{r}
#Transform daterated into a date variable in am_data as well so R can recognize as date variable

am_data$daterated <- lubridate::mdy(am_data$daterated)

#Remove DateTime column from df 
am_data = subset(am_data, select = -c(DateTime))

```

```{r}
replace_empty_with_na <- function(data) {
  data %>% mutate_if(is.character, ~ ifelse(. == "", NA, .))
}

xymerge <- function(dat) {
  # Create a logical vector indicating which column names end in ".x"
  x_cols <- grepl("\\.x$", names(dat))
  
  # Loop over each x column and apply the ifelse function
  for (x_col in names(dat)[x_cols]) {
    # Extract the corresponding y column name
    y_col <- gsub("\\.x$", ".y", x_col)
    
    # Create a new column name by removing the .x suffix
    new_col <- gsub("\\.x$", "", x_col)
    
    # Apply the ifelse function to the x and y columns and assign the result to the new column
    dat[[new_col]] <- ifelse(is.na(dat[[x_col]]), dat[[y_col]], dat[[x_col]])
    
    # Remove the x and y columns from the dataframe
    dat[[x_col]] <- NULL
    dat[[y_col]] <- NULL
  }
  
  # Return the updated data frame
  return(dat)
}
#replace empty with NA so they're coded the same for subsequent functions 
am_data <- replace_empty_with_na(am_data)
pm_data <- replace_empty_with_na(pm_data)
#consolidate xy variable names that existed as a byproduct of merging the two datasets with the same column names
am_data <- xymerge(am_data)
pm_data <- xymerge(pm_data)
```

#relocate daterated to be after ID and remove time column 
```{r}
am_data <- am_data %>% 
  relocate(daterated, .after = ID) 
pm_data <- pm_data %>% 
  relocate(daterated, .after = ID) 
```

```{r}
#Add _am and _pm suffixes to each dataset 
colnames(am_data) <- paste(colnames(am_data), "am", sep="_")

colnames(pm_data) <- paste(colnames(pm_data), "pm", sep="_")
```

```{r}
#rename daterated and ID to drop the _am and _pm suffixes 
colnames(am_data)[colnames(am_data) == "daterated_am"] ="daterated"
colnames(pm_data)[colnames(pm_data) == "daterated_pm"] ="daterated"

colnames(am_data)[colnames(am_data) == "ID_am"] ="ID"
colnames(pm_data)[colnames(pm_data) == "ID_pm"] ="ID"
```

#Remove rows where everything is NA except daterated, time, and ID
```{r}
am_data <- am_data %>% drop_na(daterated, ID)
pm_data <- pm_data %>% drop_na(daterated, ID)
```

#Remove X_pm column from pm_data 
```{r}
pm_data = subset(pm_data, select=-c(X_pm))
```

#drop ID 127 per Annie Griffith's recommendation (not much data for this ID)
```{r}

am_data <- subset(am_data, ID != 127)

pm_data <- subset(pm_data, ID != 127)

```

#Find Duplicates in Dates per ID for am_data
```{r}
result.am <- am_data %>%
  group_by(ID, daterated) %>%
  summarise(observations = n())

dupdate_am <- subset(result.am, observations != 1)
dupdate_am

result.pm <- pm_data %>%
  group_by(ID, daterated) %>%
  summarise(observations = n())

dupdate_pm <- subset(result.pm, observations != 1)
dupdate_pm
```

#Remove am_data rows so that we no longer have >1 submission per am or pm data per date. Kept earliest timestamp if all submissions are identical, or kept most complete form if some are more completed than others. 
```{r}
#remove duplicates for 106 on 2021-05-09 
am_data %>%
  filter(ID == 106 & daterated == ymd("2021-05-09"))

am_data <- am_data[!(am_data$ID == 106 & am_data$daterated == "2021-05-09" & am_data$time_am == "10:02"), ]
am_data <- am_data[!(am_data$ID == 106 & am_data$daterated == "2021-05-09" & am_data$time_am == "9:59"), ]

#remove duplicates for 106 on 2021-05-18 
am_data <- am_data[!(am_data$ID == 106 & am_data$daterated == "2021-05-18" & am_data$time_am == "6:35"), ]

#remove duplicates for 106 on 2021-05-20 
am_data <- am_data[!(am_data$ID == 106 & am_data$daterated == "2021-05-20" & am_data$time_am == "4:50"), ]

#remove duplicates for 106 on 2021-05-24 
am_data <- am_data[!(am_data$ID == 106 & am_data$daterated == "2021-05-24" & am_data$time_am == "21:59"), ]
am_data <- am_data[!(am_data$ID == 106 & am_data$daterated == "2021-05-24" & am_data$time_am == "22:00"), ]
am_data <- am_data[!(am_data$ID == 106 & am_data$daterated == "2021-05-24" & am_data$time_am == "22:02"), ]

#remove duplicates for 112 on 2021-06-28 
am_data <- am_data[!(am_data$ID == 112 & am_data$daterated == "2021-06-28" & am_data$time_am == "4:58"), ]

#remove duplicates for 112 on 2021-07-11
am_data <- am_data[!(am_data$ID == 112 & am_data$daterated == "2021-07-11" & am_data$time_am == "18:38"), ] 

#remove duplicates for 113 on 2021-06-23 
am_data <- am_data[!(am_data$ID == 113 & am_data$daterated == "2021-06-23" & am_data$time_am == "14:34"), ] 

#remove duplicates for 113 on 2021-07-07 
am_data <- am_data[!(am_data$ID == 113 & am_data$daterated == "2021-07-07" & am_data$time_am == "11:57"), ] 

#remove duplicates for 113 on 2021-07-21
am_data <- am_data[!(am_data$ID == 113 & am_data$daterated == "2021-07-21" & am_data$time_am == "11:12"), ] 

#remove duplicates for 114 on 2021-06-29
am_data <- am_data[!(am_data$ID == 114 & am_data$daterated == "2021-06-29" & am_data$time_am == "22:00"), ] 

#remove duplicates for 114 on 2021-07-01 
am_data <- am_data[!(am_data$ID == 114 & am_data$daterated == "2021-07-01 " & am_data$time_am == "9:33"), ] 

#remove duplicates for 114 on 2021-07-04 
am_data <- am_data[!(am_data$ID == 114 & am_data$daterated == "2021-07-04" & am_data$time_am == "5:58"), ] 

#remove duplicates for 114 on 2021-07-06
am_data <- am_data[!(am_data$ID == 114 & am_data$daterated == "2021-07-06" & am_data$time_am == "4:52"), ] 

#remove duplicates for 114 on 2021-07-09 
am_data <- am_data[!(am_data$ID == 114 & am_data$daterated == "2021-07-09" & am_data$time_am == "21:44"), ] 
am_data <- am_data[!(am_data$ID == 114 & am_data$daterated == "2021-07-09" & am_data$time_am == "21:45"), ] 

#remove duplicates for 114 on 2021-07-15
am_data <- am_data[!(am_data$ID == 114 & am_data$daterated == "2021-07-15" & am_data$time_am == "7:44"), ] 

#remove duplicates for 115 on 2021-06-24 
am_data <- am_data[!(am_data$ID == 115 & am_data$daterated == "2021-06-24" & am_data$time_am == "6:52"), ] 

#remove duplicates for 115 on 2021-06-27
am_data <- am_data[!(am_data$ID == 115 & am_data$daterated == "2021-06-27" & am_data$time_am == "8:27"), ] 

#remove duplicates for 115 on 2021-07-01
am_data <- am_data[!(am_data$ID == 115 & am_data$daterated == "2021-07-01" & am_data$time_am == "19:53"), ] 

#remove duplicates for 115 on 2021-07-04
am_data <- am_data[!(am_data$ID == 115 & am_data$daterated == "2021-07-04" & am_data$time_am == "3:00"), ] 
#remove duplicates for 115 on 2021-07-09 
am_data <- am_data[!(am_data$ID == 115 & am_data$daterated == "2021-07-09" & am_data$time_am == "21:49"), ] 
am_data <- am_data[!(am_data$ID == 115 & am_data$daterated == "2021-07-09" & am_data$time_am == "21:52"), ] 
am_data <- am_data[!(am_data$ID == 115 & am_data$daterated == "2021-07-09" & am_data$time_am == "21:55"), ] 
am_data <- am_data[!(am_data$ID == 115 & am_data$daterated == "2021-07-09" & am_data$time_am == "22:01"), ] 

#remove duplicates for 115 on 2021-07-11
am_data <- am_data[!(am_data$ID == 115 & am_data$daterated == "2021-07-11" & am_data$time_am == "8:38"), ] 
am_data <- am_data[!(am_data$ID == 115 & am_data$daterated == "2021-07-11" & am_data$time_am == "8:41"), ] 

#remove duplicates for 115 on 2021-07-20 
am_data <- am_data[!(am_data$ID == 115 & am_data$daterated == "2021-07-20" & am_data$time_am == "6:50"), ] 
am_data <- am_data[!(am_data$ID == 115 & am_data$daterated == "2021-07-20" & am_data$time_am == "6:57"), ] 
am_data <- am_data[!(am_data$ID == 115 & am_data$daterated == "2021-07-20" & am_data$time_am == "7:00"), ] 
am_data <- am_data[!(am_data$ID == 115 & am_data$daterated == "2021-07-20" & am_data$time_am == "7:04"), ] 
am_data <- am_data[!(am_data$ID == 115 & am_data$daterated == "2021-07-20" & am_data$time_am == "7:06"), ] 
am_data <- am_data[!(am_data$ID == 115 & am_data$daterated == "2021-07-20" & am_data$time_am == "7:09"), ] 
am_data <- am_data[!(am_data$ID == 115 & am_data$daterated == "2021-07-20" & am_data$time_am == "7:13"), ]

#remove duplicates for 118 on 2021-08-08
am_data <- am_data[!(am_data$ID == 118 & am_data$daterated == "2021-08-08" & am_data$time_am == "12:29"), ] 

#remove duplicates for 119 on 2021-08-27
am_data <- am_data[!(am_data$ID == 119 & am_data$daterated == "2021-08-27" & am_data$time_am == "21:42"), ] 

#remove duplicates for 123 on 2021-08-31
am_data <- am_data[!(am_data$ID == 123 & am_data$daterated == "2021-08-31" & am_data$time_am == "5:05"), ] 

#remove duplicates for 131 on 2021-10-17 
am_data <- am_data[!(am_data$ID == 131 & am_data$daterated == "2021-10-17" & am_data$time_am == "22:16"), ] 

#remove duplicates for ID 136 on 2021-11-29 
am_data <- am_data[!(am_data$ID == 136 & am_data$daterated == "2021-11-29" & am_data$time_am == "12:56"), ] 

#remove duplicates for ID 141 on 2022-02-01
am_data <- am_data[!(am_data$ID == 141 & am_data$daterated == "2022-02-01" & am_data$time_am == "7:30"), ] 
#remove duplicates for ID 149 on 2022-06-13
am_data <- am_data[!(am_data$ID == 149 & am_data$daterated == "2022-06-13" & am_data$time_am == "13:57"), ] 

#remove duplicates for ID 159 on 2022-07-17
am_data <- am_data[!(am_data$ID == 159 & am_data$daterated == "2022-07-17" & am_data$time_am == "9:59"), ] 

#remove duplicates for ID 159 on 2022-08-05
am_data <- am_data[!(am_data$ID == 159 & am_data$daterated == "2022-08-05" & am_data$time_am == "9:59"), ] 

#remove duplicates for ID 161 on 2022-08-12
am_data <- am_data[!(am_data$ID == 161 & am_data$daterated == "2022-08-12" & am_data$time_am == "6:30"), ] 

#remove duplicates for ID 166 on 2022-09-15
am_data <- am_data[!(am_data$ID == 166 & am_data$daterated == "2022-09-15" & am_data$time_am == "10:52"), ] 

#remove duplicates for 171 on 2022-10-21 
am_data <- am_data[!(am_data$ID == 171 & am_data$daterated == "2022-10-21" & am_data$time_am == "13:03"), ] 

#remove duplicates for 180 on 2023-03-26
am_data <- am_data[!(am_data$ID == 180 & am_data$daterated == "2023-03-26" & am_data$time_am == "2:42"), ] 

#remove duplicates for 181 on 2023-03-22
am_data <- am_data[!(am_data$ID == 181 & am_data$daterated == "2023-03-22" & am_data$time_am == "13:46"), ] 
```

#Remove pm_data rows so that we no longer have >1 submission per am or pm data per date. Kept earliest timestamp if all submissions are identical, or kept most complete form if some are more completed than others.
```{r}
#use this code to filter data pm_data %>%
  #filter(ID == x & daterated == ymd("x"))
#ID 106
pm_data <- pm_data[!(pm_data$ID == 106 & pm_data$daterated == "2021-05-08" & pm_data$time_pm == "10H 0M 0S"), ]
pm_data <- pm_data[!(pm_data$ID == 106 & pm_data$daterated == "2021-05-13" & pm_data$time_pm == "4H 57M 0S"), ]
pm_data <- pm_data[!(pm_data$ID == 106 & pm_data$daterated == "2021-05-19" & pm_data$time_pm == "4H 52M 0S"), ]
pm_data <- pm_data[!(pm_data$ID == 106 & pm_data$daterated == "2021-05-22" & pm_data$time_pm == "10H 32M 0S"), ]
pm_data <- pm_data[!(pm_data$ID == 106 & pm_data$daterated == "2021-05-23" & pm_data$time_pm == "13H 8M 0S"), ]
pm_data <- pm_data[!(pm_data$ID == 106 & pm_data$daterated == "2021-05-24" & pm_data$time_pm == "7H 18M 0S"), ]
#ID 107
pm_data <- pm_data[!(pm_data$ID == 107 & pm_data$daterated == "2021-05-29" & pm_data$time_pm == "7H 18M 0S"), ]

#ID 109 
pm_data <- pm_data[!(pm_data$ID == 109 & pm_data$daterated == "2021-06-22" & pm_data$time_pm == "20H 30M 0S"), ]

#ID 113 
pm_data <- pm_data[!(pm_data$ID == 113 & pm_data$daterated == "2021-06-29" & pm_data$time_pm == "21H 25M 0S"), ]
pm_data <- pm_data[!(pm_data$ID == 113 & pm_data$daterated == "2021-07-02" & pm_data$time_pm == "23H 03M 0S"), ]
pm_data <- pm_data[!(pm_data$ID == 113 & pm_data$daterated == "2021-07-05" & pm_data$time_pm == "0H 21M 0S"), ]
#ID 114
pm_data <- pm_data[!(pm_data$ID == 114 & pm_data$daterated == "2021-07-03" & pm_data$time_pm == "5H 57M 0S"), ]
pm_data <- pm_data[!(pm_data$ID == 114 & pm_data$daterated == "2021-07-05" & pm_data$time_pm == "4H 46M 0S"), ]
pm_data <- pm_data[!(pm_data$ID == 114 & pm_data$daterated == "2021-07-09" & pm_data$time_pm == "21H 43M 0S"), ]
pm_data <- pm_data[!(pm_data$ID == 114 & pm_data$daterated == "2021-07-09" & pm_data$time_pm == "21H 44M 0S"), ]
pm_data <- pm_data[!(pm_data$ID == 114 & pm_data$daterated == "2021-07-11" & pm_data$time_pm == "20H 46M 0S"), ]
pm_data <- pm_data[!(pm_data$ID == 114 & pm_data$daterated == "2021-07-14" & pm_data$time_pm == "7H 48M 0S"), ]
#ID 115 
pm_data %>%
  filter(ID == 115 & daterated == ymd("2021-06-26"))
pm_data <- pm_data[!(pm_data$ID == 115 & pm_data$daterated == "2021-06-26" & pm_data$time_pm == "8H 20M 0S"), ]
pm_data %>%
  filter(ID == 115 & daterated == ymd("2021-06-28"))
pm_data <- pm_data[!(pm_data$ID == 115 & pm_data$daterated == "2021-06-28" & pm_data$time_pm == "22H 1M 0S"), ]
pm_data %>%
  filter(ID == 115 & daterated == ymd("2021-07-01"))
pm_data <- pm_data[!(pm_data$ID == 115 & pm_data$daterated == "2021-07-01" & pm_data$time_pm == "19H 52M 0S"), ]
pm_data %>%
  filter(ID == 115 & daterated == ymd("2021-07-03"))
pm_data <- pm_data[!(pm_data$ID == 115 & pm_data$daterated == "2021-07-03" & pm_data$time_pm == "3H 5M 0S"), ]
pm_data %>%
  filter(ID == 115 & daterated == ymd("2021-07-09"))
pm_data <- pm_data[!(pm_data$ID == 115 & pm_data$daterated == "2021-07-09" & pm_data$time_pm == "21H 52M 0S"), ]
pm_data <- pm_data[!(pm_data$ID == 115 & pm_data$daterated == "2021-07-09" & pm_data$time_pm == "21H 54M 0S"), ]
pm_data <- pm_data[!(pm_data$ID == 115 & pm_data$daterated == "2021-07-09" & pm_data$time_pm == "21H 57M 0S"), ]
pm_data %>%
  filter(ID == 115 & daterated == ymd("2021-07-10"))
pm_data <- pm_data[!(pm_data$ID == 115 & pm_data$daterated == "2021-07-10" & pm_data$time_pm == "8H 37M 0S"), ]
pm_data <- pm_data[!(pm_data$ID == 115 & pm_data$daterated == "2021-07-10" & pm_data$time_pm == "8H 40M 0S"), ]
pm_data %>%
  filter(ID == 115 & daterated == ymd("2021-07-19"))
pm_data <- pm_data[!(pm_data$ID == 115 & pm_data$daterated == "2021-07-19" & pm_data$time_pm == "6H 48M 0S"), ]
pm_data <- pm_data[!(pm_data$ID == 115 & pm_data$daterated == "2021-07-19" & pm_data$time_pm == "6H 56M 0S"), ]
pm_data <- pm_data[!(pm_data$ID == 115 & pm_data$daterated == "2021-07-19" & pm_data$time_pm == "6H 59M 0S"), ]
pm_data <- pm_data[!(pm_data$ID == 115 & pm_data$daterated == "2021-07-19" & pm_data$time_pm == "7H 3M 0S"), ]
pm_data <- pm_data[!(pm_data$ID == 115 & pm_data$daterated == "2021-07-19" & pm_data$time_pm == "7H 6M 0S"), ]
pm_data <- pm_data[!(pm_data$ID == 115 & pm_data$daterated == "2021-07-19" & pm_data$time_pm == "7H 8M 0S"), ]
pm_data <- pm_data[!(pm_data$ID == 115 & pm_data$daterated == "2021-07-19" & pm_data$time_pm == "7H 10M 0S"), ]
pm_data <- pm_data[!(pm_data$ID == 115 & pm_data$daterated == "2021-07-19" & pm_data$time_pm == "7H 12M 0S"), ]

#ID 118 
pm_data <- pm_data[!(pm_data$ID == 118 & pm_data$daterated == "2021-08-08" & pm_data$time_pm == "12H 26M 0S"), ]
#ID 119 
pm_data <- pm_data[!(pm_data$ID == 119 & pm_data$daterated == "2021-08-03" & pm_data$time_pm == "21H 58M 0S"), ]
pm_data <- pm_data[!(pm_data$ID == 119 & pm_data$daterated == "2021-08-08" & pm_data$time_pm == "20H 50M 0S"), ]
pm_data <- pm_data[!(pm_data$ID == 119 & pm_data$daterated == "2021-08-13" & pm_data$time_pm == "5H 37M 0S"), ]
pm_data <- pm_data[!(pm_data$ID == 119 & pm_data$daterated == "2021-08-20" & pm_data$time_pm == "23H 28M 0S"), ]
pm_data <- pm_data[!(pm_data$ID == 119 & pm_data$daterated == "2021-08-22" & pm_data$time_pm == "5H 40M 0S"), ]
pm_data <- pm_data[!(pm_data$ID == 119 & pm_data$daterated == "2021-08-24" & pm_data$time_pm == "16H 23M 0S"), ]
pm_data <- pm_data[!(pm_data$ID == 119 & pm_data$daterated == "2021-08-27" & pm_data$time_pm == "21H 40M 0S"), ]
#ID 136
pm_data <- pm_data[!(pm_data$ID == 136 & pm_data$daterated == "2021-11-29" & pm_data$time_pm == "17H 10M 0S"), ]
#ID 138
pm_data <- pm_data[!(pm_data$ID == 138 & pm_data$daterated == "2022-02-06" & pm_data$time_pm == "12H 21M 0S"), ]
#ID 143
pm_data <- pm_data[!(pm_data$ID == 143 & pm_data$daterated == "2022-01-31" & pm_data$time_pm == "17H 04M 0S"), ]
#ID 149
pm_data <- pm_data[!(pm_data$ID == 149 & pm_data$daterated == "2022-05-25" & pm_data$time_pm == "0H 42M 0S"), ]
pm_data <- pm_data[!(pm_data$ID == 149 & pm_data$daterated == "2022-06-10" & pm_data$time_pm == "12H 20M 0S"), ]
#ID 150
pm_data <- pm_data[!(pm_data$ID == 150 & pm_data$daterated == "2022-06-07" & pm_data$time_pm == "21H 34M 0S"), ]
#ID 153
pm_data <- pm_data[!(pm_data$ID == 153 & pm_data$daterated == "2022-06-23" & pm_data$time_pm == "8H 24M 0S"), ]
#ID 159
pm_data <- pm_data[!(pm_data$ID == 159 & pm_data$daterated == "2022-07-17" & pm_data$time_pm == "6H 40M 0S"), ]
#ID 168
pm_data <- pm_data[!(pm_data$ID == 168 & pm_data$daterated == "2022-09-25" & pm_data$time_pm == "20H 23M 0S"), ]
pm_data <- pm_data[!(pm_data$ID == 168 & pm_data$daterated == "2022-10-09" & pm_data$time_pm == "18H 47M 0S"), ]
#ID 171
pm_data <- pm_data[!(pm_data$ID == 171 & pm_data$daterated == "2022-10-07" & pm_data$time_pm == "0H 10M 0S"), ]
pm_data <- pm_data[!(pm_data$ID == 171 & pm_data$daterated == "2022-10-13" & pm_data$time_pm == "12H 34M 0S"), ]
pm_data <- pm_data[!(pm_data$ID == 171 & pm_data$daterated == "2022-10-31" & pm_data$time_pm == "20H 36M 0S"), ]
#ID 180
pm_data <- pm_data[!(pm_data$ID == 180 & pm_data$daterated == "2023-04-15" & pm_data$time_pm == "22H 7M 0S"), ]
#ID 181
pm_data <- pm_data[!(pm_data$ID == 181 & pm_data$daterated == "2023-03-22" & pm_data$time_pm == "19H 13M 0S"), ]
#ID 185
pm_data <- pm_data[!(pm_data$ID == 185 & pm_data$daterated == "2023-05-29" & pm_data$time_pm == "23H 34M 0S"), ]
```

### functions to create person means and person deviations
```{r echo=T}
#function to create person means

create.person.mean <- function(am_data, Urge_Alc_am, Urg_Nic_am, Urg_Mar_am, Alc_Amt_am) {
  am_data %>%
    group_by(ID) %>%
    mutate("{{Urge_Alc_am, Urg_Nic_am, Urg_Mar_am, Alc_Amt_am}}.m" := mean({{Urge_Alc_am, Urg_Nic_am, Urg_Mar_am, Alc_Amt_am}}, na.rm=T))
}
create.person.mean

create.person.mean <- function(df, var, ...) {
  df %>%
    group_by(...) %>%
    mutate("{{var}}.m" := mean({{var}}, na.rm=T))
}

#simplified the process below 
am_data <- am_data %>% group_by(ID) %>% mutate(Urg_Alc_am.m = mean(Urg_Alc_am, na.rm = T),
                                               Urg_Nic_am.m = mean(Urg_Nic_am, na.rm = T),
                                               Urg_Mar_am.m = mean(Urg_Mar_am, na.rm = T),
                                               Urg_Coc_am.m = mean(Urg_Coc_am, na.rm = T),
                                               Urg_Oth_am.m = mean(Urg_Oth_am, na.rm = T)
                                               )

create.person.mean(am_data, Urge_Alc_am)

#function to create person deviations (note, must have person means already made)
create.deviation <- function(am_data, var, var.m) {
  df <- df %>%
    rowwise() %>%
    mutate("{{var}}.d" := {{var}} - {{var.m}})
}

create.3day.rolling.avg <- function(df, var, num) {
  df %>%
    group_by(id) %>%
    mutate("{{var}}.roll" := rollapply({{var}}, 3,  mean, align="center", fill=NA))
}


```

## create outcome lists to loop through functions
```{r echo=T}

#raw outcomes
suimed_varlist <- suimeddata %>%
  select(c(BAM2_stirredupscream,
           DRSP7_angirr,
           DRSP4_anxious,
           perceivedburden,
           DRSP8_intconflict,
           DRSP1_depblue,
           DRSP2_hopeless,
           DRSP16_overwhelm,
           DRSP6_rejsens,
           DRSP9_lessintmot,
           DRSP3_worthguilt,
           ASIQ9_wishdead,
           SI,
           SI_Final)) %>% 
  colnames() %>% 
  noquote()
#suimed_varlist <- suimed_varlist[-1]

#person-centered deviations
suimed_varlist.d <- c("BAM2_stirredupscream.d",
           "DRSP7_angirr.d",
           "DRSP4_anxious.d",
           "perceivedburden.d",
           "DRSP8_intconflict.d",
           "DRSP1_depblue.d",
           "DRSP2_hopeless.d",
           "DRSP16_overwhelm.d",
           "DRSP6_rejsens.d",
           "DRSP9_lessintmot.d",
           "DRSP3_worthguilt.d",
           "ASIQ9_wishdead.d",
           "SI.d",
           "SI_Final.d") %>% noquote()

#rolling averages
suimed_varlist.roll <- c("BAM2_stirredupscream.roll",
           "DRSP7_angirr.roll",
           "DRSP4_anxious.roll",
           "perceivedburden.roll",
           "DRSP8_intconflict.roll",
           "DRSP1_depblue.roll",
           "DRSP2_hopeless.roll",
           "DRSP16_overwhelm.roll",
           "DRSP6_rejsens.roll",
           "DRSP9_lessintmot.roll",
           "DRSP3_worthguilt.roll",
           "ASIQ9_wishdead.roll",
           "SI.roll",
           "SI_Final.roll") %>% noquote()


```

#test 2/10/23: create rolling average BEFORE means and deviations

### *execute functions* \n
#to get a list of all person means: \n
paste0(outcomelist,".m") \n
# to run create.deviation() one at a time. \n
c2d <- create.deviation(c2d, wishsleep, wishsleep.m) \n
#to run create.person.mean() one at a time. \n
 c2d <- create.person.mean(c2d, ASIQ4_thoughtwhen, id)
```{r}

#create rolling averages on RAW variables
for (i in suimed_varlist) {
  suimeddata_cycleday <- create.3day.rolling.avg(suimeddata_cycleday, !!sym({{i}}))
}

  
#execute for loop: run create.person.mean() on everything in "outcomelist.roll"
for (i in suimed_varlist.roll) {
  suimeddata_cycleday <- create.person.mean(suimeddata_cycleday, !!sym({{i}}), id)
}
#execute for loop: run create.deviation() on everything in list
for (i in suimed_varlist.roll) {
  suimeddata_cycleday <- create.deviation(suimeddata_cycleday, !!sym({{i}}), !!sym(paste0({{i}}, ".m")))
}


#execute for loop: run create.deviation() on everything in list - non rolling avg
for (i in suimed_varlist) {
  suimeddata_cycleday <- create.deviation(suimeddata_cycleday, !!sym({{i}}), !!sym(paste0({{i}}, ".m")))
}

```


#Find values for each outcome that end in .d and put those in raincloud plot 

## IF OUTCOME IS LINEAR, function is "lmer" not "glmer"
# rest of syntax is the same, including * for interaction and placement of random effect terms
model6 <- lmer(DMQsocial_today~legalage+age.z+covidrestrictions+
                                   currentdx_SUDalc+currentdx_SUDnonalc+frisatsun+
                                   LH_perimenstrual_count+LH_midluteal_count+LH_midfol_LH
                                 +(1+LH_midluteal_count+
                                     LH_midfol_LH+
                                     LH_perimenstrual_count | id), 
                                 control=lmerControl(optimizer="optimx",
                                                     optCtrl=list(method='nlminb')),
                                 data = etoh_data_motives)

```{r}


nullmodel <- lmer(Urg_Alc_am~ (1 | ID),
                                 data = am_data)

summary(nullmodel)
icc(nullmodel)


```


#Save cleaned files as csv files
```{r}
write.csv(am_data, "/Users/apatte21/Library/CloudStorage/Box-Box/00 - CLEAR Lab (Locked Folders)/02 - Data Management, Analysis, and Papers/Studies_Projects/UKALC/02_datasets/UKALC_DAILY/03_cleaned_data/am_data_cleaned.csv", row.names=TRUE)

write.csv(pm_data, "/Users/apatte21/Library/CloudStorage/Box-Box/00 - CLEAR Lab (Locked Folders)/02 - Data Management, Analysis, and Papers/Studies_Projects/UKALC/02_datasets/UKALC_DAILY/03_cleaned_data/pm_data_cleaned.csv", row.names=TRUE)
```

#Filter out variables of interest from am_data 
```{r}
am_datashort <- am_data %>% select(ID,
                          daterated,
                          Mar_am,
                          Alc_Amt_am,
                          Alc_Time_am,
                          Alc_Dur_am,
                          Alc_Drunk_am,
                          Alc_Drunk_txt_am)
am_datashort
#make histogram of alcohol amount am 
#make Alc_Amt_am numeric first 
am_datashort$Alc_Amt_am <- as.numeric(am_datashort$Alc_Amt_am)
hist(am_datashort$Alc_Amt_am)
am_datashort$Alc_Drunk_am <- as.numeric(am_datashort$Alc_Drunk_am)
hist(am_datashort$Alc_Drunk_am)

#create a new variable that's did you drink -> 1 not drink -> 0 
#create new variable heavy drinking (>4) -> 1 , <4 gets 0 
#how many people used alcohol at all 
#raincloud plots for each variable 
#calculate interclass correlations within person for each possible outcome (0 means all w/in person variance, 1 is between person variance)
```
#Filter out variables of interest from pm_data 
```{r}
pm_datashort <- pm_data %>% select(ID,
                          daterated,
                          Urg_Alc_pm,
                          Urg_Mar_pm,
                          Urg_Nic_pm,
                          Sp_Food_Crav_pm,
                          OverEat_pm,
                          Diff_Inhib_pm,
                          Diff_Stop_pm,
                          Loss_Control_pm,
                          )
pm_datashort
#makae variables of interest numberic before making histograms 
pm_datashort$Urg_Alc_pm <- as.numeric(pm_datashort$Urg_Alc_pm)
hist(pm_datashort$Urg_Alc_pm)
```

#Add in cycle day 
```{r}

cycle.day <- read.csv("/Users/apatte21/Library/CloudStorage/Box-Box/00 - CLEAR Lab (Locked Folders)/02 - Data Management, Analysis, and Papers/Studies_Projects/UKALC/02_datasets/UKALC_DAILY/02_data_prep_workspace/UKAlc.Cycle.Day.csv")

```

#Merge in cycle day data 
```{r}
#use janitor package to make sure the 2 datasets can be merged
#return=mismatch will return only columns that cannot merge

cycle.day$daterated <- mdy(cycle.day$daterated)

cycleday.am.merge <- merge(cycle.day, am_data, by = c("ID", "daterated"), all = T)
cycleday.pm.merge <- merge(cycle.day, pm_data, by = c("ID", "daterated"), all = T)



```
#Add in LH Data
```{r}
LH.Count <- read.csv("/Users/apatte21/Library/CloudStorage/Box-Box/00 - CLEAR Lab (Locked Folders)/02 - Data Management, Analysis, and Papers/Studies_Projects/UKALC/02_datasets/UKALC_DAILY/02_data_prep_workspace/UKAlc.LH.Data.csv")

LH.Count$daterated <- ymd(LH.Count$daterated)

cycleday.am.merge <- merge(LH.Count, cycleday.am.merge, by = c("ID", "daterated"), all = T)
cycleday.pm.merge <- merge(LH.Count, cycleday.pm.merge, by = c("ID", "daterated"), all = T)

write_csv(cycleday.am.merge, "Cycle_Day_LH_menses_am.csv")
write_csv(cycleday.pm.merge, "Cycle_Day_LH_menses_pm.csv")
```


```{r cyclephase_count}

cycleday.am.merge <- cycleday.am.merge %>% 
  mutate(midluteal_count = ifelse(cycleday >= -9 & cycleday <= -5, 1, 0),
         perimenstrual_count = ifelse(cycleday >=-3 & cycleday <=2, 1, 0),
         midfol_count = ifelse(cycleday >=4 & cycleday <=7, 1, 0),
         periov_count = ifelse(cycleday >= -15 & cycleday <= -12, 1, 0))

#add a non-dummy coded variable with all of cycle phase info above, which will be useful for future visualizations and summaries
cycleday.am.merge <- cycleday.am.merge %>% mutate(cyclephase_count = case_when(periov_count==1 ~ 1,
                                                     midluteal_count==1 ~ 2,
                                                     perimenstrual_count==1 ~ 3,
                                                     midfol_count==1 ~ 4,
                                                     TRUE ~ as.numeric(NA)))

cycleday.pm.merge <- cycleday.pm.merge %>% 
  mutate(midluteal_count = ifelse(cycleday >= -9 & cycleday <= -5, 1, 0),
         perimenstrual_count = ifelse(cycleday >=-3 & cycleday <=2, 1, 0),
         midfol_count = ifelse(cycleday >=4 & cycleday <=7, 1, 0),
         periov_count = ifelse(cycleday >= -15 & cycleday <= -12, 1, 0))

#add a non-dummy coded variable with all of cycle phase info above, which will be useful for future visualizations and summaries
cycleday.pm.merge <- cycleday.pm.merge %>% mutate(cyclephase_count = case_when(periov_count==1 ~ 1,
                                                     midluteal_count==1 ~ 2,
                                                     perimenstrual_count==1 ~ 3,
                                                     midfol_count==1 ~ 4,
                                                     TRUE ~ as.numeric(NA)))



```
#This LH cyclephase code is adapted from github repository: code_templates/prep_Cycle Phase Coding 5 phase - ADHD-KY.Rmd starting at step 5a 
```{r cyclephase_LH}

cycleday.am.merge <- cycleday.am.merge %>% 
  mutate(midluteal_LH = ifelse(daycountLH >= 6 & daycountLH <= 10, 1, 0),
         perimenstrual_LH = ifelse(cycleday >=-3 & cycleday <=2, 1, 0), #note perimenstrual is based on cycleday
         midfol_LH = ifelse(daycountLH >=-7 & daycountLH <=-3, 1, 0),
         periov_LH = ifelse(daycountLH >= -2 & daycountLH <= 1, 1, 0),
         earlylut_LH = ifelse(daycountLH >= 2 & daycountLH <= 5, 1, 0))

#fill out the dummy code, so that if any phase is 1, all others should be 0 (not NA)
cycleday.am.merge <- cycleday.am.merge %>%
  rowwise() %>%
  mutate(sumdummy = sum(midfol_LH,
                        periov_LH,
                        earlylut_LH,
                        perimenstrual_LH,
                        midluteal_LH, na.rm = T)) %>% 
  #if all phases=0, make the midluteal_LH variable NA instead of 0,
  #if perimenstrual by menses count = 1, change midluteal_LH to 0 instead of NA to fill out structural set,
  #otherwise, keep as is
  mutate(midluteal_LH = case_when(sumdummy==0 ~ as.numeric(NA),
                                  sumdummy==1 & perimenstrual_LH==1 ~ 0,
                                  TRUE ~ midluteal_LH), 
         #same for midfol
         midfol_LH = case_when(sumdummy==0 ~ as.numeric(NA),
                               sumdummy==1 & perimenstrual_LH==1 ~ 0,
                               TRUE ~ midfol_LH), 
          #same for periov
         periov_LH = case_when(sumdummy==0 ~ as.numeric(NA),
                               sumdummy==1 & perimenstrual_LH==1 ~ 0,
                               TRUE ~ periov_LH),
         earlylut_LH = case_when(sumdummy==0 ~ as.numeric(NA),
                                  sumdummy==1 & perimenstrual_LH==1 ~ 0,
                                  TRUE ~ earlylut_LH), 
         #if any other phase is 1, fill out perimenstrual to be 0
         perimenstrual_LH = case_when(sumdummy==0 ~ as.numeric(NA), 
                                        sumdummy==1 & midfol_LH==1 ~ 0,
                                        sumdummy==1 & periov_LH==1 ~ 0,
                                      sumdummy==1 & earlylut_LH==1 ~ 0,
                                        sumdummy==1 & midluteal_LH==1 ~ 0,
                                        TRUE ~ perimenstrual_LH))

#add a non-dummy coded variable with all of cycle phase info above, which will be useful for future visualizations and summaries
cycleday.am.merge <- cycleday.am.merge %>% mutate(cyclephase_LH = case_when(periov_LH==1 ~ 1,
                                                                        earlylut_LH==1 ~ 2,
                                                     midluteal_LH==1 ~ 3,
                                                     perimenstrual_LH==1 ~ 4,
                                                     midfol_LH==1 ~ 5,
                                                     TRUE ~ as.numeric(NA)))

```

```{r cyclephase_LH}

cycleday.pm.merge <- cycleday.pm.merge %>% 
  mutate(midluteal_LH = ifelse(daycountLH >= 6 & daycountLH <= 10, 1, 0),
         perimenstrual_LH = ifelse(cycleday >=-3 & cycleday <=2, 1, 0), #note perimenstrual is based on cycleday
         midfol_LH = ifelse(daycountLH >=-7 & daycountLH <=-3, 1, 0),
         periov_LH = ifelse(daycountLH >= -2 & daycountLH <= 1, 1, 0),
         earlylut_LH = ifelse(daycountLH >= 2 & daycountLH <= 5, 1, 0))

#fill out the dummy code, so that if any phase is 1, all others should be 0 (not NA)
cycleday.pm.merge <- cycleday.pm.merge %>%
  rowwise() %>%
  mutate(sumdummy = sum(midfol_LH,
                        periov_LH,
                        earlylut_LH,
                        perimenstrual_LH,
                        midluteal_LH, na.rm = T)) %>% 
  #if all phases=0, make the midluteal_LH variable NA instead of 0,
  #if perimenstrual by menses count = 1, change midluteal_LH to 0 instead of NA to fill out structural set,
  #otherwise, keep as is
  mutate(midluteal_LH = case_when(sumdummy==0 ~ as.numeric(NA),
                                  sumdummy==1 & perimenstrual_LH==1 ~ 0,
                                  TRUE ~ midluteal_LH), 
         #same for midfol
         midfol_LH = case_when(sumdummy==0 ~ as.numeric(NA),
                               sumdummy==1 & perimenstrual_LH==1 ~ 0,
                               TRUE ~ midfol_LH), 
          #same for periov
         periov_LH = case_when(sumdummy==0 ~ as.numeric(NA),
                               sumdummy==1 & perimenstrual_LH==1 ~ 0,
                               TRUE ~ periov_LH),
         earlylut_LH = case_when(sumdummy==0 ~ as.numeric(NA),
                                  sumdummy==1 & perimenstrual_LH==1 ~ 0,
                                  TRUE ~ earlylut_LH), 
         #if any other phase is 1, fill out perimenstrual to be 0
         perimenstrual_LH = case_when(sumdummy==0 ~ as.numeric(NA), 
                                        sumdummy==1 & midfol_LH==1 ~ 0,
                                        sumdummy==1 & periov_LH==1 ~ 0,
                                      sumdummy==1 & earlylut_LH==1 ~ 0,
                                        sumdummy==1 & midluteal_LH==1 ~ 0,
                                        TRUE ~ perimenstrual_LH))

#add a non-dummy coded variable with all of cycle phase info above, which will be useful for future visualizations and summaries
cycleday.pm.merge <- cycleday.pm.merge %>% mutate(cyclephase_LH = case_when(periov_LH==1 ~ 1,
                                                                        earlylut_LH==1 ~ 2,
                                                     midluteal_LH==1 ~ 3,
                                                     perimenstrual_LH==1 ~ 4,
                                                     midfol_LH==1 ~ 5,
                                                     TRUE ~ as.numeric(NA)))

```
  
```{r}

#check overlaps: goal is to only have 6 possible group combinations here (1 row per dummy coded phase, then a row where ALL are NA)
cycleday.am.merge %>%
  group_by(periov_LH, earlylut_LH, midluteal_LH, perimenstrual_LH, midfol_LH) %>%
  summarize(n=n())
#make note of errors


#example code to review midfol_LH and perimenstrual_LH overlaps, if they exist
cycleday.am.merge %>%
  filter(midfol_LH==1) %>%
  filter(perimenstrual_LH==1) %>%
  select(id, daterated, posLHtoday, daycountLH,
         menstrualbleeding,
         firstdayofperiod, cycleday,
         midfol_LH, periov_LH, earlylut_LH,
         midluteal_LH, perimenstrual_LH) %>%
  View()



```                                                                        

```{r}

#check overlaps: goal is to only have 6 possible group combinations here (1 row per dummy coded phase, then a row where ALL are NA)
cycleday.pm.merge %>%
  group_by(periov_LH, earlylut_LH, midluteal_LH, perimenstrual_LH, midfol_LH) %>%
  summarize(n=n())
#make note of errors


#example code to review midfol_LH and perimenstrual_LH overlaps, if they exist
cycleday.pm.merge %>%
  filter(midfol_LH==1) %>%
  filter(perimenstrual_LH==1) %>%
  select(id, daterated, posLHtoday, daycountLH,
         menstrualbleeding,
         firstdayofperiod, cycleday,
         midfol_LH, periov_LH, earlylut_LH,
         midluteal_LH, perimenstrual_LH) %>%
  View()



```    
     
#edit days that got double-counted
```{r}

cycleday.am.merge  <- cycleday.am.merge  %>%
  #if perimenstrual by firstdayofperiod and midfol by pre-LH count are both 1, perimen wins, make midfol=0
  mutate(midfol_LH = case_when(perimenstrual_LH==1 ~ 0,
                                        TRUE ~ midfol_LH)) 

#review midlut and perimens overlaps - can override midluteal with perimens IF luteal phase is short but still seems normal (such as 9-10 days)
## make notes of any SUPER short luteal phases (like 4-5 days) that you might want to flag for anovulation
cycleday.am.merge %>% filter(midluteal_LH==1 & perimenstrual_LH==1) %>% 
  select(ID, daterated, daycountLH, cycleday, midluteal_LH, perimenstrual_LH)

#code for if you are ready to override midluteals with perimens
cycleday.am.merge  <- cycleday.am.merge  %>%
  #if perimenstrual by firstdayofperiod and midlut by count after LH test are both 1, perimen wins, make midlut=0
  mutate(midluteal_LH = case_when(perimenstrual_LH==1 ~ 0,
                                        TRUE ~ midluteal_LH)) 

## ANY OTHER COMBOS need hand review!!

#good practice to review again and ensure that dummy code is fixed
cycleday.am.merge %>%
  group_by(periov_LH, earlylut_LH, midluteal_LH, perimenstrual_LH, midfol_LH) %>%
  summarize(n=n())

```                                                                        

```{r}

cycleday.pm.merge  <- cycleday.pm.merge  %>%
  #if perimenstrual by firstdayofperiod and midfol by pre-LH count are both 1, perimen wins, make midfol=0
  mutate(midfol_LH = case_when(perimenstrual_LH==1 ~ 0,
                                        TRUE ~ midfol_LH)) 

#review midlut and perimens overlaps - can override midluteal with perimens IF luteal phase is short but still seems normal (such as 9-10 days)
## make notes of any SUPER short luteal phases (like 4-5 days) that you might want to flag for anovulation
cycleday.pm.merge %>% filter(midluteal_LH==1 & perimenstrual_LH==1) %>% 
  select(ID, daterated, daycountLH, cycleday, midluteal_LH, perimenstrual_LH)

#code for if you are ready to override midluteals with perimens
cycleday.pm.merge  <- cycleday.pm.merge  %>%
  #if perimenstrual by firstdayofperiod and midlut by count after LH test are both 1, perimen wins, make midlut=0
  mutate(midluteal_LH = case_when(perimenstrual_LH==1 ~ 0,
                                        TRUE ~ midluteal_LH)) 

## ANY OTHER COMBOS need hand review!!

#good practice to review again and ensure that dummy code is fixed
cycleday.pm.merge %>%
  group_by(periov_LH, earlylut_LH, midluteal_LH, perimenstrual_LH, midfol_LH) %>%
  summarize(n=n())

```    

```{r}
cycleday.am.merge %>% write.csv("Cycleday.am.LH.menses.data.csv")
```

#Look at data to be sure the cycle phases are typical lengths. This is in the code chunks I just copy/pasted from Jordan's code. 
#next steps are to look at variability within each variable of interest across time (NOT cycle phase) so just do daterated on x, variable on y 
#as factor for each variable, then rename levels as factors - update data dictionary so you know max/min when factoring. Then do as numeric. It may automatically do numeric but double-check. 
#Calculate luteal phase by subtracting the period start date column by posov_pred column but group by person first! 
#create a new variable that's did you drink -> 1 not drink -> 0 
#create new variable heavy drinking (>4) -> 1 , <4 gets 0 
####do person means centered code and then make histogram of all the data regardless of what time is. Don't do time or cycle phase. 




