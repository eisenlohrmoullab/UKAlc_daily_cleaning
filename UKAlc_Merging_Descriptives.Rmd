---
title: "UKAlc_Merging_Descriptives"
author: "Anna Patterson"
date: "2023-09-28"
output: html_document
---

rm(list = ls())
```{r}
#libraries
library(tidyverse)
library(dplyr)
library(tidyr)
library(stringr)
library(janitor)
library(lubridate)
knitr::opts_chunk$set(echo = TRUE)

#Anisha's Paths

# 
# am_qual <- read.csv("C:/Users/anish/Box/00 - CLEAR Lab (Locked Folders)/02 - Data Management, Analysis, and Papers/Studies_Projects/UKALC/02_datasets/UKALC_DAILY/02_data_prep_workspace/AM_Qualtrics_csv.csv")
# 
# pm_qual <- read.csv("C:/Users/anish/Box/00 - CLEAR Lab (Locked Folders)/02 - Data Management, Analysis, and Papers/Studies_Projects/UKALC/02_datasets/UKALC_DAILY/02_data_prep_workspace/PM_Qualtrics_csv.csv")
# 
# am_rc <- read.csv("C:/Users/anish/Box/00 - CLEAR Lab (Locked Folders)/02 - Data Management, Analysis, and Papers/Studies_Projects/UKALC/02_datasets/UKALC_DAILY/02_data_prep_workspace/AM_REDCap_csv.csv")
# 
# pm_rc <- read.csv("C:/Users/anish/Box/00 - CLEAR Lab (Locked Folders)/02 - Data Management, Analysis, and Papers/Studies_Projects/UKALC/02_datasets/UKALC_DAILY/02_data_prep_workspace/PM_REDCap_csv.csv")


#Anna's Paths

am_qual <- read.csv("/Users/apatte21/Library/CloudStorage/Box-Box/00 - CLEAR Lab (Locked Folders)/02 - Data Management, Analysis, and Papers/Studies_Projects/UKALC/02_datasets/UKALC_DAILY/02_data_prep_workspace/AM_Qualtrics_csv.csv")

pm_qual <- read.csv("/Users/apatte21/Library/CloudStorage/Box-Box/00 - CLEAR Lab (Locked Folders)/02 - Data Management, Analysis, and Papers/Studies_Projects/UKALC/02_datasets/UKALC_DAILY/02_data_prep_workspace/PM_Qualtrics_csv.csv")

am_rc <- read.csv("/Users/apatte21/Library/CloudStorage/Box-Box/00 - CLEAR Lab (Locked Folders)/02 - Data Management, Analysis, and Papers/Studies_Projects/UKALC/02_datasets/UKALC_DAILY/02_data_prep_workspace/AM_REDCap_csv.csv")

pm_rc <- read.csv("/Users/apatte21/Library/CloudStorage/Box-Box/00 - CLEAR Lab (Locked Folders)/02 - Data Management, Analysis, and Papers/Studies_Projects/UKALC/02_datasets/UKALC_DAILY/02_data_prep_workspace/PM_REDCap_csv.csv")
```

ID's in am_qual: 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 126

ID's in a_rc: [1] "123"       "124"       "125"       "125b"      "125c"      "125d"      "127"       "127 (new)" "128"      
[10] "129"       "130"       "131"       "132"       "133"       "134"       "134b"      "135"       "136"      
[19] "138"       "139"       "139b"      "140"       "141"       "142"       "142b"      "143"       "144"      
[28] "145"       "146"       "147"       "148"       "149"       "150"       "152"       "153"       "154"      
[37] "155"       "156"       "157"       "158"       "159"       "160"       "161"       "162"       "163"      
[46] "164"       "165"       "166"       "166a"      "166b"      "167"       "168"       "169"       "170"      
[55] "171"       "172"       "173"       "174"       "175"       "176"       "177"       "178"       "179"      
[64] "180"       "181"       "182"       "183"       "184"       "185"   

ID's in pm_qual: 101 102 103 104 105 106 107 108 109 111 112 113 114 115 116 117 118 119 120 121 122 126 

ID's in pm_rc: [1] "123"       "124"       "125"       "125b"      "125c"      "125d"      "127"       "127 (new)" "128"      
[10] "129"       "130"       "131"       "132"       "133"       "134"       "134b"      "135"       "136"      
[19] "138"       "139"       "139b"      "140"       "141"       "142"       "142b"      "143"       "144"      
[28] "145"       "146"       "147"       "148"       "149"       "150"       "152"       "153"       "154"      
[37] "155"       "156"       "157"       "158"       "159"       "160"       "161"       "162"       "163"      
[46] "164"       "165"       "166"       "166a"      "166b"      "167"       "168"       "169"       "170"      
[55] "171"       "172"       "173"       "174"       "175"       "176"       "177"       "178"       "179"      
[64] "180"       "181"       "182"       "183"       "184"       "185"    



#IDs in am qualtrics are numerical, IDs in rc are string form -- letters at end of some IDs indicate different sessions of same participant 
```{r}
am_data <- merge(am_qual, am_rc, by = c("ID", "DateTime"), all = T)

pm_data <- merge(pm_qual, pm_rc, by = c("ID", "DateTime"), all = T)

```
#view overlap between am and pm data 
#See how many unique IDs are in each dataset 
```{r}
intersect(am_data$ID, pm_data$ID)

setdiff(am_data$ID, pm_data$ID)

am_pm_part <- intersect(am_data$ID, pm_data$ID)
length(am_pm_part)

am_data$ID <- gsub("[^0-9.-]", "", am_data$ID)
pm_data$ID <- gsub("[^0-9.-]", "", pm_data$ID)

#seeing how many IDs are in each data set, viewed the output and saw they included NA in the calculation, so subtracted 1 from final calculation 
length(unique(am_data$ID))
length(unique(pm_data$ID))
```

#Before correcting for duplicates, we have n = 83 for am data and n = 82 for pm data 

#Transform DateRated into date and time type variables 
```{r}
##What Anna tried to make DateRated into date and time variables## 
#library(lubridate)

# pm_data$DateTime <- as_datetime(pm_data$DateTime)
# #the line above also made all the DateTimes into NAs 
# #one way I tried to change DateTime from df into date/time type 
# #I suspect maybe this isn't working because there are NAs? 
# pm_data$DateTime <- lubridate::mdy_hms(pm_data$DateTime)
# #the line above made all the DateTimes into NAs 
# #another way I tried to change DateTime from df into date/time type 
# pm_data <- data.frame(pm_data$DateTime = as.POSIXct(c(DateTime)))
# #another way I tried to change DateTime from df into date/time type 
# pm_data$DateTime <- pm_data %>% mutate(DateTime = mdy_hms(DateTime))
# #yet another way                   
# as.POSIXct(pm_data, format = "%d-%b-%y")
# pm_data <- data.frame(pm_data = c(DateTime)) 
# pm_data$DateTime_ap <- as.POSIXct(pm_data$DateTime, format = "%Y-%m-%d %H:%M:%S")

```



```{r}
#separate datetime variable 
am_data[c('daterated', 'time')] <- str_split_fixed(am_data$DateTime, ' ', 2)
pm_data[c('daterated', 'time')] <- str_split_fixed(pm_data$DateTime, ' ', 2)
```


#Examine pm_data surveys that were completed before 12:00pm and assigned them to the day prior if no prior day survey completed 

1. Flag observations that were done before 12pm
2. check if for those observations, there was a prior day survey 
3. if not, assign those to the prior day 

```{r}
#first step change time character to a time-realized variable 
pm_data$time <- lubridate::hm(pm_data$time)
pm_data$daterated <- lubridate::mdy(pm_data$daterated)

#flag observations that were done before 12pm 
pm_data <- pm_data %>% mutate(pm_data, b4noon = ifelse(time < lubridate::hm("12:00"),1, 0)) 

  #this below here was initially a pipe with line 136  
#select(ID, daterated, time, DateTime, b4noon) 

#if b4noon = 1, change pm_data$daterated - 1

pm_data <- pm_data %>%
  mutate(daterated = case_when(
    b4noon == 1 ~ daterated -1,
    TRUE ~ daterated
  ))

 

#pm_data %>% select(ID, daterated, time, DateTime, b4noon) 

#daterated variable still here after running above line without line 148 
```

```{r}
#Transform daterated into a date variable so R can recognize as date variable

am_data$daterated <- lubridate::mdy(am_data$daterated)
#pm_data$daterated <- lubridate::mdy(pm_data$daterated) #the issue with daterated variable dissappearing when looking for duplicates appears to be this line. When I ran the code with this line and the other line on this R chunk commented out, the dupdate function worked. 

#Remove DateTime column from df 
am_data = subset(am_data, select = -c(DateTime))
#pm_data = subset(pm_data, select = -c(DateTime))
```

```{r}
replace_empty_with_na <- function(data) {
  data %>% mutate_if(is.character, ~ ifelse(. == "", NA, .))
}

xymerge <- function(dat) {
  # Create a logical vector indicating which column names end in ".x"
  x_cols <- grepl("\\.x$", names(dat))
  
  # Loop over each x column and apply the ifelse function
  for (x_col in names(dat)[x_cols]) {
    # Extract the corresponding y column name
    y_col <- gsub("\\.x$", ".y", x_col)
    
    # Create a new column name by removing the .x suffix
    new_col <- gsub("\\.x$", "", x_col)
    
    # Apply the ifelse function to the x and y columns and assign the result to the new column
    dat[[new_col]] <- ifelse(is.na(dat[[x_col]]), dat[[y_col]], dat[[x_col]])
    
    # Remove the x and y columns from the dataframe
    dat[[x_col]] <- NULL
    dat[[y_col]] <- NULL
  }
  
  # Return the updated data frame
  return(dat)
}

#replace empty with NA so they're coded the same for subsequent functions 
am_data <- replace_empty_with_na(am_data)
pm_data <- replace_empty_with_na(pm_data)
#consolidate xy variable names that existed as a byproduct of merging the two datasets with the same column names
am_data <- xymerge(am_data)
pm_data <- xymerge(pm_data)
```

#relocate daterated to be after ID and remove time column 
```{r}
am_data <- am_data %>% 
  relocate(daterated, .after = ID) 
pm_data <- pm_data %>% 
  relocate(daterated, .after = ID) 
```


```{r}
#Add _am and _pm suffixes to each dataset 
colnames(am_data) <- paste(colnames(am_data), "am", sep="_")

colnames(pm_data) <- paste(colnames(pm_data), "pm", sep="_")
```

```{r}
#rename daterated and ID to drop the _am and _pm suffixes 
colnames(am_data)[colnames(am_data) == "daterated_am"] ="daterated"
colnames(pm_data)[colnames(pm_data) == "daterated_pm"] ="daterated"

colnames(am_data)[colnames(am_data) == "ID_am"] ="ID"
colnames(pm_data)[colnames(pm_data) == "ID_pm"] ="ID"
```


#Remove rows where everything is NA except daterated, time, and ID
```{r}
am_data <- am_data %>% drop_na(daterated, ID)
pm_data <- pm_data %>% drop_na(daterated, ID)
```

#drop ID 127 per Annie Griffith's recommendation (not much data for this ID)
```{r}

am_data <- subset(am_data, ID != 127)

pm_data <- subset(pm_data, ID != 127)

```

#Find Duplicates in Dates per ID for am_data
```{r}
result.am <- am_data %>%
  group_by(ID, daterated) %>%
  summarise(observations = n())

dupdate_am <- subset(result.am, observations != 1)
dupdate_am

result.pm <- pm_data %>%
  group_by(ID, daterated) %>%
  summarise(observations = n())

dupdate_pm <- subset(result.pm, observations != 1)
dupdate_pm
```

#Remove am_data rows so that we no longer have >1 submission per am or pm data per date. Kept earliest timestamp if all submissions are identical, or kept most complete form if some are more completed than others. 
```{r}
#remove duplicates for 106 on 2021-05-09 
am_data %>%
  filter(ID == 106 & daterated == ymd("2021-05-09"))

am_data <- am_data[!(am_data$ID == 106 & am_data$daterated == "2021-05-09" & am_data$time_am == "10:02"), ]
am_data <- am_data[!(am_data$ID == 106 & am_data$daterated == "2021-05-09" & am_data$time_am == "9:59"), ]

#remove duplicates for 106 on 2021-05-18 
am_data <- am_data[!(am_data$ID == 106 & am_data$daterated == "2021-05-18" & am_data$time_am == "6:35"), ]

#remove duplicates for 106 on 2021-05-20 
am_data <- am_data[!(am_data$ID == 106 & am_data$daterated == "2021-05-20" & am_data$time_am == "4:50"), ]

#remove duplicates for 106 on 2021-05-24 
am_data <- am_data[!(am_data$ID == 106 & am_data$daterated == "2021-05-24" & am_data$time_am == "21:59"), ]
am_data <- am_data[!(am_data$ID == 106 & am_data$daterated == "2021-05-24" & am_data$time_am == "22:00"), ]
am_data <- am_data[!(am_data$ID == 106 & am_data$daterated == "2021-05-24" & am_data$time_am == "22:02"), ]

#remove duplicates for 112 on 2021-06-28 
am_data <- am_data[!(am_data$ID == 112 & am_data$daterated == "2021-06-28" & am_data$time_am == "4:58"), ]

#remove duplicates for 112 on 2021-07-11
am_data <- am_data[!(am_data$ID == 112 & am_data$daterated == "2021-07-11" & am_data$time_am == "18:38"), ] 

#remove duplicates for 113 on 2021-06-23 
am_data <- am_data[!(am_data$ID == 113 & am_data$daterated == "2021-06-23" & am_data$time_am == "14:34"), ] 

#remove duplicates for 113 on 2021-07-07 
am_data <- am_data[!(am_data$ID == 113 & am_data$daterated == "2021-07-07" & am_data$time_am == "11:57"), ] 

#remove duplicates for 113 on 2021-07-21
am_data <- am_data[!(am_data$ID == 113 & am_data$daterated == "2021-07-21" & am_data$time_am == "11:12"), ] 

#remove duplicates for 114 on 2021-06-29
am_data <- am_data[!(am_data$ID == 114 & am_data$daterated == "2021-06-29" & am_data$time_am == "22:00"), ] 

#remove duplicates for 114 on 2021-07-01 
am_data <- am_data[!(am_data$ID == 114 & am_data$daterated == "2021-07-01 " & am_data$time_am == "9:33"), ] 

#remove duplicates for 114 on 2021-07-04 
am_data <- am_data[!(am_data$ID == 114 & am_data$daterated == "2021-07-04" & am_data$time_am == "5:58"), ] 

#remove duplicates for 114 on 2021-07-06
am_data <- am_data[!(am_data$ID == 114 & am_data$daterated == "2021-07-06" & am_data$time_am == "4:52"), ] 

#remove duplicates for 114 on 2021-07-09 
am_data <- am_data[!(am_data$ID == 114 & am_data$daterated == "2021-07-09" & am_data$time_am == "21:44"), ] 
am_data <- am_data[!(am_data$ID == 114 & am_data$daterated == "2021-07-09" & am_data$time_am == "21:45"), ] 

#remove duplicates for 114 on 2021-07-15
am_data <- am_data[!(am_data$ID == 114 & am_data$daterated == "2021-07-15" & am_data$time_am == "7:44"), ] 

#remove duplicates for 115 on 2021-06-24 
am_data <- am_data[!(am_data$ID == 115 & am_data$daterated == "2021-06-24" & am_data$time_am == "6:52"), ] 

#remove duplicates for 115 on 2021-06-27
am_data <- am_data[!(am_data$ID == 115 & am_data$daterated == "2021-06-27" & am_data$time_am == "8:27"), ] 

#remove duplicates for 115 on 2021-07-01
am_data <- am_data[!(am_data$ID == 115 & am_data$daterated == "2021-07-01" & am_data$time_am == "19:53"), ] 

#remove duplicates for 115 on 2021-07-04
am_data <- am_data[!(am_data$ID == 115 & am_data$daterated == "2021-07-04" & am_data$time_am == "3:00"), ] 
#remove duplicates for 115 on 2021-07-09 
am_data <- am_data[!(am_data$ID == 115 & am_data$daterated == "2021-07-09" & am_data$time_am == "21:49"), ] 
am_data <- am_data[!(am_data$ID == 115 & am_data$daterated == "2021-07-09" & am_data$time_am == "21:52"), ] 
am_data <- am_data[!(am_data$ID == 115 & am_data$daterated == "2021-07-09" & am_data$time_am == "21:55"), ] 
am_data <- am_data[!(am_data$ID == 115 & am_data$daterated == "2021-07-09" & am_data$time_am == "22:01"), ] 

#remove duplicates for 115 on 2021-07-11
am_data <- am_data[!(am_data$ID == 115 & am_data$daterated == "2021-07-11" & am_data$time_am == "8:38"), ] 
am_data <- am_data[!(am_data$ID == 115 & am_data$daterated == "2021-07-11" & am_data$time_am == "8:41"), ] 

#remove duplicates for 115 on 2021-07-20 
am_data <- am_data[!(am_data$ID == 115 & am_data$daterated == "2021-07-20" & am_data$time_am == "6:50"), ] 
am_data <- am_data[!(am_data$ID == 115 & am_data$daterated == "2021-07-20" & am_data$time_am == "6:57"), ] 
am_data <- am_data[!(am_data$ID == 115 & am_data$daterated == "2021-07-20" & am_data$time_am == "7:00"), ] 
am_data <- am_data[!(am_data$ID == 115 & am_data$daterated == "2021-07-20" & am_data$time_am == "7:04"), ] 
am_data <- am_data[!(am_data$ID == 115 & am_data$daterated == "2021-07-20" & am_data$time_am == "7:06"), ] 
am_data <- am_data[!(am_data$ID == 115 & am_data$daterated == "2021-07-20" & am_data$time_am == "7:09"), ] 
am_data <- am_data[!(am_data$ID == 115 & am_data$daterated == "2021-07-20" & am_data$time_am == "7:13"), ]

#remove duplicates for 118 on 2021-08-08
am_data <- am_data[!(am_data$ID == 118 & am_data$daterated == "2021-08-08" & am_data$time_am == "12:29"), ] 

#remove duplicates for 119 on 2021-08-27
am_data <- am_data[!(am_data$ID == 119 & am_data$daterated == "2021-08-27" & am_data$time_am == "21:42"), ] 

#remove duplicates for 123 on 2021-08-31
am_data <- am_data[!(am_data$ID == 123 & am_data$daterated == "2021-08-31" & am_data$time_am == "5:05"), ] 

#remove duplicates for 131 on 2021-10-17 
am_data <- am_data[!(am_data$ID == 131 & am_data$daterated == "2021-10-17" & am_data$time_am == "22:16"), ] 

#remove duplicates for ID 136 on 2021-11-29 
am_data <- am_data[!(am_data$ID == 136 & am_data$daterated == "2021-11-29" & am_data$time_am == "12:56"), ] 

#remove duplicates for ID 141 on 2022-02-01
am_data <- am_data[!(am_data$ID == 141 & am_data$daterated == "2022-02-01" & am_data$time_am == "7:30"), ] 
#remove duplicates for ID 149 on 2022-06-13
am_data <- am_data[!(am_data$ID == 149 & am_data$daterated == "2022-06-13" & am_data$time_am == "13:57"), ] 

#remove duplicates for ID 159 on 2022-07-17
am_data <- am_data[!(am_data$ID == 159 & am_data$daterated == "2022-07-17" & am_data$time_am == "9:59"), ] 

#remove duplicates for ID 159 on 2022-08-05
am_data <- am_data[!(am_data$ID == 159 & am_data$daterated == "2022-08-05" & am_data$time_am == "9:59"), ] 

#remove duplicates for ID 161 on 2022-08-12
am_data <- am_data[!(am_data$ID == 161 & am_data$daterated == "2022-08-12" & am_data$time_am == "6:30"), ] 

#remove duplicates for ID 166 on 2022-09-15
am_data <- am_data[!(am_data$ID == 166 & am_data$daterated == "2022-09-15" & am_data$time_am == "10:52"), ] 

#remove duplicates for 171 on 2022-10-21 
am_data <- am_data[!(am_data$ID == 171 & am_data$daterated == "2022-10-21" & am_data$time_am == "13:03"), ] 

#remove duplicates for 180 on 2023-03-26
am_data <- am_data[!(am_data$ID == 180 & am_data$daterated == "2023-03-26" & am_data$time_am == "2:42"), ] 

#remove duplicates for 181 on 2023-03-22
am_data <- am_data[!(am_data$ID == 181 & am_data$daterated == "2023-03-22" & am_data$time_am == "13:46"), ] 
```

#Remove pm_data rows so that we no longer have >1 submission per am or pm data per date. Kept earliest timestamp if all submissions are identical, or kept most complete form if some are more completed than others.
```{r}
#use this code to filter data pm_data %>%
  #filter(ID == x & daterated == ymd("x"))
#ID 106
pm_data <- pm_data[!(pm_data$ID == 106 & pm_data$daterated == "2021-05-08" & pm_data$time_pm == "10H 0M 0S"), ]
pm_data <- pm_data[!(pm_data$ID == 106 & pm_data$daterated == "2021-05-13" & pm_data$time_pm == "4H 57M 0S"), ]
pm_data <- pm_data[!(pm_data$ID == 106 & pm_data$daterated == "2021-05-19" & pm_data$time_pm == "4H 52M 0S"), ]
pm_data <- pm_data[!(pm_data$ID == 106 & pm_data$daterated == "2021-05-22" & pm_data$time_pm == "10H 32M 0S"), ]
pm_data <- pm_data[!(pm_data$ID == 106 & pm_data$daterated == "2021-05-23" & pm_data$time_pm == "13H 8M 0S"), ]
pm_data <- pm_data[!(pm_data$ID == 106 & pm_data$daterated == "2021-05-24" & pm_data$time_pm == "7H 18M 0S"), ]
#ID 107
pm_data <- pm_data[!(pm_data$ID == 107 & pm_data$daterated == "2021-05-29" & pm_data$time_pm == "7H 18M 0S"), ]

#ID 109 
pm_data <- pm_data[!(pm_data$ID == 109 & pm_data$daterated == "2021-06-22" & pm_data$time_pm == "20H 30M 0S"), ]

#ID 113 
pm_data %>%
  filter(ID == 113 & daterated == ymd("2021-06-29"))
pm_data <- pm_data[!(pm_data$ID == 113 & pm_data$daterated == "2021-06-29" & pm_data$time_pm == "21H 25M 0S"), ]
pm_data %>%
  filter(ID == 113 & daterated == ymd("2021-07-02"))
pm_data <- pm_data[!(pm_data$ID == 113 & pm_data$daterated == "2021-07-02" & pm_data$time_pm == "23H 03M 0S"), ]
pm_data %>%
  filter(ID == 113 & daterated == ymd("2021-07-05"))
pm_data <- pm_data[!(pm_data$ID == 113 & pm_data$daterated == "2021-07-05" & pm_data$time_pm == "0H 21M 0S"), ]
#ID 114
pm_data %>%
  filter(ID == 114 & daterated == ymd("2021-07-03"))
pm_data <- pm_data[!(pm_data$ID == 114 & pm_data$daterated == "2021-07-03" & pm_data$time_pm == "5H 57M 0S"), ]
pm_data %>%
  filter(ID == 114 & daterated == ymd("2021-07-05"))
pm_data <- pm_data[!(pm_data$ID == 114 & pm_data$daterated == "2021-07-05" & pm_data$time_pm == "4H 46M 0S"), ]
pm_data %>%
  filter(ID == 114 & daterated == ymd("2021-07-09"))
pm_data <- pm_data[!(pm_data$ID == 114 & pm_data$daterated == "2021-07-09" & pm_data$time_pm == "21H 43M 0S"), ]
pm_data <- pm_data[!(pm_data$ID == 114 & pm_data$daterated == "2021-07-09" & pm_data$time_pm == "21H 44M 0S"), ]
pm_data %>%
  filter(ID == 114 & daterated == ymd("2021-07-11"))
pm_data <- pm_data[!(pm_data$ID == 114 & pm_data$daterated == "2021-07-11" & pm_data$time_pm == "20H 46M 0S"), ]
pm_data %>%
  filter(ID == 114 & daterated == ymd("2021-07-14"))
pm_data <- pm_data[!(pm_data$ID == 114 & pm_data$daterated == "2021-07-14" & pm_data$time_pm == "7H 48M 0S"), ]

```


#Filter out variables of interest from am_data 
```{r}
am_datashort <- am_data %>% select(ID,
                          daterated,
                          Mar_am,
                          Alc_Amt_am,
                          Alc_Time_am,
                          Alc_Dur_am,
                          Alc_Drunk_am,
                          Alc_Drunk_txt_am)
am_datashort
#make histogram of alcohol amount am 
#make Alc_Amt_am numeric first 
am_datashort$Alc_Amt_am <- as.numeric(am_datashort$Alc_Amt_am)
hist(am_datashort$Alc_Amt_am)

#merge in date of menses/ovulation, then calculate cycle day **merge in menses start dates 
#I can even output this smaller dataset into excel file and input menses start dates as 1s 
#transfer menses start dates in and keep notes about people who don't have a start date, and use template for coding when 
#you don't have the LH start day --> use this to make a graph for onset of menses 
#create a new variable that's did you drink -> 1 not drink -> 0 
#create new variable heavy drinking (>4) -> 1 , <4 gets 0 
```


#Previous Day Survey Check Before Removing PM Duplicates 

```{r}
#For each duplicate of completed surveys for a person, check if they completed the previous day survey. If they did not, it means they could have meant the earlier time duplicate for the previous day. Rather than excluding these from the study as duplicates, I will re-assign them to the prior day so that we can have the most robust/inclusive dataset possible.

#Anna: I don't think I need this part anymore, but will double-check before deleting. 

# pm_dupes <- pm_data %>% 
#   get_dupes(ID, daterated)
# pm_data <- pm_data %>%
#   left_join(pm_dupes)
# pm_data$dupe_count[is.na(pm_data$dupe_count)] <- 0
# 
# priordaydupe <- function(x) {
#   x$ID <- as.numeric(x$ID)
#   x <- x %>% group_by(ID) %>% arrange(daterated)
#   y <- x
#   count = 0
#   n = unique(x$ID)
#   for (i in n) {
#     iddat <- subset(y, ID == i)
#     m = dim(iddat)[1]
#     for (j in 1:m) {
#       if (!is.na(iddat$dupe_count[j]) && iddat$dupe_count[j] == 2) {
#         count = count + 1
#         b = (iddat$daterated[j])
#         if (!(as.Date(b - 1) %in% iddat$daterated)) {
#           print(paste('The survey does not exist for the day before', b, "for the id number", i))
#         }
#       }
#     }
#   }
#   print(paste('There are', count, 'surveys where the same daterated is recorded, by participant'))
# }

#priordaydupe(pm_data) 
#This will only work if the date variable is called daterated
```


```{r}
##Anna in progress##
# changedatepm <- function(id, time, olddate, newdate){
#   pm_data %>%
#   mutate(daterated = case_when(
#     ID== id & time_pm == time & daterated == mdy(olddate) ~ mdy(newdate),
#     TRUE ~ daterated
#   ))
#   
# }
# #filter each priordaydupe ID to examine duplicates and changedatepm if applicable 
# pm_data%>% filter(ID == 109)%>% select(ID, daterated, time_pm)
# #changing 4/20 first dup to 4/19
# pm_data <- pm_data %>%
#   mutate(daterated = case_when(
#     ID== 103 & time_pm == "0:05" & daterated == mdy("4/20/21") ~ mdy("4/19/21"),
#     TRUE ~ daterated
#   ))
# 
# #ID 103 
# pm_data <- changedatepm(103, "0:05", "4/20/21","4/19/21")
# pm_data <- changedatepm(103, "1:58", "4/24/21","4/23/21")
# pm_data <- changedatepm(103, "0:12", "4/26/21","4/25/21")
# pm_data <- changedatepm(103, "1:55", "5/09/21","5/08/21")
# #ID 105
# pm_data <- changedatepm(105, "6:08", "5/09/21","5/08/21")
# pm_data <- changedatepm(105, "9:03", "5/07/21","5/06/21")
# pm_data <- changedatepm(105, "7:11", "5/13/21","5/12/21")
# pm_data <- changedatepm(105, "7:09", "5/18/21","5/17/21")
# #ID 106
# pm_data <- changedatepm(106, "8:50", "5/12/21","5/11/21")
# #ID 107 
# pm_data <- changedatepm(107, "4:35", "5/25/21","5/24/21")
# pm_data <- changedatepm(107, "5:19", "6/06/21","6/05/21")
# #ID 108
# pm_data <- changedatepm(108, "0:46", "6/16/21","6/15/21")
# pm_data <- changedatepm(108, "9:45", "6/20/21","6/19/21")
# #ID 109 
# pm_data <- changedatepm(109, "0:08", "6/07/21","6/06/21")
# pm_data <- changedatepm(109, "6:17", "6/13/21","6/12/21")
# pm_data <- changedatepm(109, "7:44", "6/15/21","6/14/21")
# pm_data <- changedatepm(109, "9:48", "6/24/21","6/23/21")
# #ID 111
# pm_data <- changedatepm(111, "7:11", "6/20/21","6/19/21")
# pm_data <- changedatepm(111, "6:34", "6/22/21","6/21/21")
# #ID 113 
# pm_data <- changedatepm(113, "8:22", "6/18/21","6/17/21")
# pm_data <- changedatepm(113, "5:32", "6/20/21","6/19/21")
# pm_data <- changedatepm(113, "5:52", "6/23/21","6/22/21")
# pm_data <- changedatepm(113, "0:17", "7/06/21","7/05/21")
# pm_data <- changedatepm(113, "10:50", "7/11/21","7/10/21")
# pm_data <- changedatepm(113, "3:41", "7/14/21","7/13/21")
# #ID 114
# pm_data <- changedatepm(114, "8:24", "6/20/21","6/19/21")
# pm_data <- changedatepm(114, "9:36", "6/25/21","6/24/21")
# pm_data <- changedatepm(114, "5:57", "7/04/21","7/03/21")
# pm_data <- changedatepm(114, "5:59", "7/04/21","7/03/21")
# pm_data <- changedatepm(114, "4:46", "7/06/21","7/05/21")
# pm_data <- changedatepm(114, "4:51", "7/06/21","7/05/21")
# #ID 112
# pm_data <- changedatepm(112, "7:23", "6/24/21","6/23/21")
# pm_data <- changedatepm(112, "4:59", "6/28/21","6/27/21")
# pm_data <- changedatepm(112, "0:03", "7/04/21","7/03/21")
# #ID 117
# pm_data <- changedatepm(117, "1:12", "7/09/21","7/08/21")
# pm_data <- changedatepm(117, "0:38", "7/16/21","7/15/21")
# pm_data <- changedatepm(117, "8:36", "7/24/21","7/23/21")
# pm_data <- changedatepm(117, "2:11", "7/26/21","7/25/21")
# #ID 118
# pm_data <- changedatepm(118, "10:36", "8/13/21","8/12/21")
# pm_data <- changedatepm(118, "6:03", "8/15/21","8/14/21")
# pm_data <- changedatepm(118, "7:42", "8/21/21","8/20/21")
# pm_data <- changedatepm(118, "6:18", "8/25/21","8/24/21")
# pm_data <- changedatepm(118, "8:21", "9/01/21","8/31/21")
# pm_data <- changedatepm(118, "9:11", "9/05/21","9/04/21")
# #ID 124
# pm_data <- changedatepm(124, "0:05", "9/02/21","9/01/21")
# pm_data <- changedatepm(124, "0:01", "9/05/21","9/04/21")
# #ID 125
# pm_data <- changedatepm(125, "10:02", "8/26/21","8/25/21")
# pm_data <- changedatepm(125, "9:49", "8/28/21","8/27/21")
# pm_data <- changedatepm(125, "9:49", "8/28/21","8/27/21")
# pm_data <- changedatepm(125, "4:57", "1/20/22","1/19/22")
# #ID 128
# pm_data <- changedatepm(128, "7:35", "8/27/21","8/26/21")
# pm_data <- changedatepm(128, "0:26", "9/04/21","9/03/21")
# pm_data <- changedatepm(128, "1:04", "9/11/21","9/10/21")
# #ID 130
# pm_data%>% filter(ID == 130)%>% select(ID, daterated, time_pm)
# pm_data <- changedatepm(130, "9:02", "9/11/21","9/10/21")
# pm_data <- changedatepm(130, "8:00", "9/03/21","9/02/21")
# pm_data <- changedatepm(130, "7:21", "9/13/21","9/12/21")
# pm_data <- changedatepm(130, "9:57", "9/25/21","9/24/21")
# #ID 129
# pm_data <- changedatepm(129, "2:01", "9/19/21","9/18/21")
# pm_data <- changedatepm(129, "0:22", "9/21/21","9/20/21")
# pm_data <- changedatepm(129, "0:22", "9/27/21","9/26/21")
# #ID 127
# pm_data <- changedatepm(127, "10:42", "9/12/21","9/11/21")
# #ID 132
# pm_data <- changedatepm(132, "0:09", "10/21/21","10/20/21")
# pm_data <- changedatepm(132, "0:21", "10/23/21","10/22/21")
# pm_data <- changedatepm(132, "0:02", "11/04/21","11/03/21")
# pm_data <- changedatepm(132, "0:05", "11/06/21","11/05/21")
# #ID 133
# pm_data <- changedatepm(133, "0:02", "11/06/21","11/05/21")
# pm_data <- changedatepm(133, "8:26", "11/18/21","11/17/21")
# pm_data <- changedatepm(133, "8:26", "11/18/21","11/17/21")
# #ID 136
# pm_data%>% filter(ID == 136)%>% select(ID, daterated, time_pm)
# pm_data <- changedatepm(136, "0:39", "12/09/21","12/08/21")
# pm_data <- changedatepm(136, "0:01", "12/16/21","12/15/21")
# pm_data <- changedatepm(136, "0:22", "12/20/21","12/19/21")
# pm_data <- changedatepm(136, "0:08", "12/22/21","12/21/21")
# pm_data <- changedatepm(136, "0:20", "12/25/21","12/24/21")
# pm_data <- changedatepm(136, "0:56", "12/30/21","12/29/21")
# #ID 138
# pm_data <- changedatepm(138, "7:02", "2/11/22","2/10/22")
# #ID 140
# pm_data <- changedatepm(140, "5:33", "2/10/22","2/09/22")
# #ID 139
# pm_data <- changedatepm(139, "4:08", "2/06/22","2/05/22")
# pm_data <- changedatepm(139, "4:33", "2/14/22","2/13/22")
# pm_data <- changedatepm(139, "0:46", "2/21/22","2/20/22")
# pm_data <- changedatepm(139, "1:52", "2/24/22","2/23/22")
# #ID 143
# pm_data <- changedatepm(143, "2:04", "2/12/22","2/11/22")
# #ID 141
# pm_data <- changedatepm(141, "7:45", "2/02/22","2/01/22")
# pm_data <- changedatepm(141, "0:01", "2/04/22","2/03/22")
# pm_data <- changedatepm(141, "0:13", "2/06/22","2/05/22")
# pm_data <- changedatepm(141, "7:24", "2/09/22","2/08/22")
# pm_data <- changedatepm(141, "6:56", "2/21/22","2/20/22")
# pm_data <- changedatepm(141, "0:02", "2/25/22","2/24/22")
# #ID 146
# pm_data <- changedatepm(146, "0:04", "3/07/22","3/06/22")
# pm_data <- changedatepm(146, "10:26", "3/27/22","3/26/22")
# #ID 145
# pm_data <- changedatepm(145, "0:08", "3/14/22","3/13/22")
# #ID 147
# pm_data <- changedatepm(147, "0:14", "4/24/22","4/23/22")
# #ID 148
# pm_data <- changedatepm(148, "0:18", "5/21/22","5/20/22")
# pm_data <- changedatepm(148, "0:34", "5/29/22","5/28/22")
# pm_data <- changedatepm(148, "0:06", "6/20/22","6/19/22")
# #ID 149
# pm_data <- changedatepm(149, "0:06", "5/31/22","5/30/22")
# #ID 150
# pm_data <- changedatepm(150, "0:34", "5/31/22","5/30/22")
# pm_data <- changedatepm(150, "12:10", "6/07/22","6/06/22")
# pm_data <- changedatepm(150, "10:53", "6/17/22","6/16/22")
# #ID 152
# pm_data <- changedatepm(152, "6:38", "7/11/22","7/10/22")
# pm_data <- changedatepm(152, "7:41", "7/14/22","7/13/22")
# #ID 154
# pm_data <- changedatepm(154, "0:00", "6/26/22","6/25/22")
# pm_data <- changedatepm(154, "0:02", "6/30/22","6/29/22")
# pm_data <- changedatepm(154, "0:36", "7/06/22","7/05/22")
# pm_data <- changedatepm(154, "1:19", "7/09/22","7/08/22")
# pm_data <- changedatepm(154, "0:24", "7/13/22","7/12/22")
# #ID 153
# pm_data <- changedatepm(153, "0:07", "6/28/22","6/27/22")
# #ID 155
# pm_data <- changedatepm(155, "0:44", "7/17/22","7/16/22")
# pm_data <- changedatepm(155, "0:19", "7/22/22","7/21/22")
# pm_data <- changedatepm(155, "3:05", "7/24/22","7/23/22")
# pm_data <- changedatepm(155, "5:20", "7/26/22","7/25/22")
# #ID 156
# pm_data <- changedatepm(156, "0:23", "7/15/22","7/14/22")
# #ID 157
# pm_data <- changedatepm(156, "1:24", "7/21/22","7/20/22")
# #ID 160
# pm_data%>% filter(ID == 160)%>% select(ID, daterated, time_pm)
# pm_data <- changedatepm(160, "0:01", "7/28/22","7/27/22")
# #ID 161
# pm_data%>% filter(ID == 161)%>% select(ID, daterated, time_pm)
# pm_data <- changedatepm(161, "0:21", "7/31/22","7/30/22")
```

#Remove pm duplicates
```{r}
result.pm <- pm_data %>%
  group_by(ID, daterated) %>%
  summarise(observations = n())

dupdate_pm <- subset(result.pm, observations != 1)
View(dupdate_pm)

#PM Duplicates 
#ID 106
##Anna: start here 
pm_data %>%
  filter(ID == 106 & daterated == ymd("2021-04-24"))
pm_data <- pm_data[!(pm_data$ID == 106 & pm_data$daterated == "" & pm_data$time_pm == ""), ] 

pm_data %>%
  filter(ID == 103 & daterated == ymd("2021-04-24"))

pm_data <- pm_data[!(pm_data$ID == 103 & pm_data$daterated == "2021-04-24" & pm_data$time_pm == ""), ] 

pm_data %>%
  filter(ID == 103 & daterated == ymd("2021-04-26"))

pm_data <- pm_data[!(pm_data$ID == 103 & pm_data$daterated == "2021-04-26" & pm_data$time_pm == "0:12"), ] 
```

#remove IDs = NA 
```{r}
#note that these four didn't seem to work 
#am_data <- am_data[!(is.na(am_data$ID)), ] 
#am_data <- am_data[!(am_data$ID == NA), ] 
#subset(am_data, !is.na(ID))
#am_data[!is.na(am_data$ID),]
#am_data %>% drop_na(ID)
#am_data %>% drop_na(daterated)
```


#Anisha's way to investigate IDs in result_am and result_pm in which obs >1 
#Note that she wrote this with the old column names - will adjust based on final column naming scheme 
pm_data %>%  
  filter(id==[INSERT ID] & daterated==mdy("[INSERT DATE]"))

am_data %>%
  filter(id==[INSERT ID] & daterated==mdy("[INSERT DATE]"))
  
Remove by time using subset. If they are exactly the same, keep the earliest one. If not, keep the most complete one. 


#Drop Time Variable 
```{r}
am_data = subset(am_data, select=-c(time_am))

pm_data = subset(pm_data, select=-c(time_pm))
```


#IDs in both am and pm datasets: 
[1] "101"       "102"       "103"       "104"       "105"       "106"       "107"       "108"       "109"      
[10] "111"       "112"       "113"       "114"       "115"       "116"       "117"       "118"       "119"      
[19] "120"       "121"       "122"       "123"       "124"       "125"       "125b"      "125c"      "125d"     
[28] "126"       "127"       "127 (new)" "128"       "129"       "130"       "131"       "132"       "133"      
[37] "134"       "134b"      "135"       "136"       "138"       "139"       "139b"      "140"       "141"      
[46] "142"       "142b"      "143"       "144"       "145"       "146"       "147"       "148"       "149"      
[55] "150"       "152"       "153"       "154"       "155"       "156"       "157"       "158"       "159"      
[64] "160"       "161"       "162"       "163"       "164"       "165"       "166"       "166a"      "166b"     
[73] "167"       "168"       "169"       "170"       "171"       "172"       "173"       "174"       "175"      
[82] "176"       "177"       "178"       "179"       "180"       "181"       "182"       "183"       "184"      
[91] "185"  



